This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-12-16T20:04:07.361Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
config/
  config.yaml.sample
embedders/
  __init__.py
  base.py
  bm25.py
  dpr.py
  minilm.py
  sbert.py
  tfidf.py
evaluation/
  test_sets/
    test_queries.json
    test_set_summary.json
  metrics.py
  visualization.py
scripts/
  utils/
    common.py
    logging_config.py
  evaluate_embeddings.py
  generate_test_set.py
  index_articles.py
  manage_qdrant.py
  search_news.py
  visualize_results.py
storage/
  __init__.py
  data_loader.py
  qdrant_manager.py
.gitignore
config.py
db_qdrant.py
env.sample
index_preprocessed.sh
index_raw.sh
README.md
requirements.txt

================================================================
Repository Files
================================================================

================
File: config/config.yaml.sample
================
qdrant:
  # For local development (Docker)
  local:
    host: localhost
    port: 6333
  # For production (Cloud)
  cloud:
    url: "https://YOUR-CLUSTER-URL.qdrant.io"
    api_key: ${QDRANT_API_KEY}

embedders:
  tfidf:
    max_features: 384

  sbert:
    model_name: "hiiamsid/sentence_similarity_spanish_es"

  dpr:
    model_name: "facebook/dpr-question_encoder-single-nq-base"

  minilm:
    model_name: "sentence-transformers/all-MiniLM-L6-v2"

processing:
  batch_size: 32
  min_words: 500
  max_words: 20000

================
File: embedders/__init__.py
================
from .base import BaseEmbedder
from .tfidf import TfidfEmbedder
from .sbert import SBERTEmbedder
from .dpr import DPREmbedder
from .minilm import MiniLMEmbedder
from .bm25 import BM25Embedder

__all__ = [
    'BaseEmbedder',
    'TfidfEmbedder',
    'SBERTEmbedder',
    'DPREmbedder',
    'MiniLMEmbedder',
    'BM25Embedder'
]

================
File: embedders/base.py
================
"""
Base Embedder Module

This module provides the abstract base class for all embedder implementations.
Each concrete embedder class must inherit from BaseEmbedder and implement
all abstract methods.
"""

from abc import ABC, abstractmethod
import numpy as np


class BaseEmbedder(ABC):
    """
    Abstract base class for all embedding models.

    This class defines the interface that all embedder implementations must follow.
    Each embedder should be able to convert text into a fixed-size vector representation
    and provide information about its vector dimensions and collection name in Qdrant.

    Methods
    -------
    embed(text: str) -> np.ndarray:
        Convert input text into a vector representation

    Properties
    ----------
    dimension: int
        The size of the output embedding vector
    collection_name: str
        The name of the collection where embeddings will be stored in Qdrant
    """

    @abstractmethod
    def embed(self, text: str) -> np.ndarray:
        """
        Convert text to embedding vector.

        Parameters
        ----------
        text : str
            The input text to be embedded

        Returns
        -------
        np.ndarray
            The embedding vector representation of the input text
        """
        pass

    @property
    @abstractmethod
    def dimension(self) -> int:
        """
        Return the dimension of the embedding vector.

        Returns
        -------
        int
            The size of the embedding vector
        """
        pass

    @property
    @abstractmethod
    def collection_name(self) -> str:
        """
        Return the name of the collection for this embedder.

        Returns
        -------
        str
            The name of the Qdrant collection where embeddings will be stored
        """
        pass

================
File: embedders/bm25.py
================
"""
BM25 Embedder Module

This module implements text embedding using the BM25 (Best Matching 25) algorithm.
BM25 is a probabilistic ranking function used for information retrieval, adapted
here to produce fixed-size vector representations compatible with vector stores.
"""

from typing import List
import numpy as np
from rank_bm25 import BM25Okapi
from .base import BaseEmbedder


class BM25Embedder(BaseEmbedder):
    """
    BM25-based text embedder.

    This embedder uses the BM25 algorithm to convert text into numerical vectors.
    It requires fitting on a corpus before it can be used for embedding. The BM25
    scores are normalized and padded/truncated to produce fixed-size vectors.

    Parameters
    ----------
    dimension : int, optional (default=384)
        Size of the output vector, matches TF-IDF dimension for consistency

    Attributes
    ----------
    bm25 : BM25Okapi or None
        The underlying BM25 model, None until fitted
    corpus : List[List[str]] or None
        The tokenized corpus used for fitting
    _dimension : int
        The fixed size of output vectors
    """

    def __init__(self):
        """Initialize the BM25 embedder."""
        self.bm25 = None
        self.corpus = None
        self._dimension = 384  # Same as TF-IDF for consistency

    def fit(self, texts: List[str]) -> None:
        """
        Fit the BM25 model on a corpus of texts.

        Parameters
        ----------
        texts : List[str]
            List of documents to prepare the BM25 model with

        Returns
        -------
        None
        """
        self.corpus = [text.split() for text in texts]
        self.bm25 = BM25Okapi(self.corpus)

    def embed(self, text: str) -> np.ndarray:
        """
        Convert text to BM25-based vector representation.

        Parameters
        ----------
        text : str
            Input text to be embedded

        Returns
        -------
        np.ndarray
            Normalized vector of BM25 scores

        Raises
        ------
        ValueError
            If the BM25 model hasn't been fitted yet
        """
        if self.bm25 is None:
            raise ValueError("BM25 needs to be fitted first")

        query_tokens = text.split()
        scores = self.bm25.get_scores(query_tokens)

        # Pad or truncate to match dimension
        if len(scores) < self.dimension:
            scores = np.pad(scores, (0, self.dimension - len(scores)))
        else:
            scores = scores[:self.dimension]

        # Normalize the scores
        norm = np.linalg.norm(scores)
        if norm > 0:
            scores = scores / norm

        return scores

    @property
    def dimension(self) -> int:
        """
        Get the dimension of the BM25 vectors.

        Returns
        -------
        int
            Fixed size of the output vectors
        """
        return self._dimension

    @property
    def collection_name(self) -> str:
        """
        Get the name of the Qdrant collection for BM25 embeddings.

        Returns
        -------
        str
            Collection name for storing BM25 embeddings
        """
        return "news_bm25"

================
File: embedders/dpr.py
================
"""
DPR Embedder Module

This module implements text embedding using Dense Passage Retrieval (DPR)
question encoder. While primarily designed for question-answering tasks,
it can be effectively used for general text embedding.
"""

import numpy as np
import torch
from transformers import AutoTokenizer, DPRQuestionEncoder
from .base import BaseEmbedder


class DPREmbedder(BaseEmbedder):
    """
    Dense Passage Retrieval (DPR) based text embedder.

    This embedder uses a pre-trained DPR question encoder to generate
    dense vector representations of text. It's particularly effective
    for query/question embedding in retrieval tasks.

    Parameters
    ----------
    model_name : str, optional (default="facebook/dpr-question_encoder-single-nq-base")
        The name or path of the pre-trained DPR model to use

    Attributes
    ----------
    tokenizer : AutoTokenizer
        Tokenizer for the DPR model
    model : DPRQuestionEncoder
        The underlying DPR model

    """

    def __init__(self, model_name: str = "facebook/dpr-question_encoder-single-nq-base"):
        """
        Initialize the DPR embedder.

        Parameters
        ----------
        model_name : str, optional
            Name or path of the pre-trained model to load
        """
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = DPRQuestionEncoder.from_pretrained(model_name)
        self.model.eval()  # Set to evaluation mode

    def embed(self, text: str) -> np.ndarray:
        """
        Convert text to DPR embedding vector.

        Parameters
        ----------
        text : str
            Input text to be embedded

        Returns
        -------
        np.ndarray
            Normalized DPR embedding vector
        """
        inputs = self.tokenizer(
            text,
            return_tensors="pt",
            max_length=512,
            truncation=True
        )
        with torch.no_grad():
            outputs = self.model(**inputs)
        # Normalize the embeddings
        embeddings = outputs.pooler_output[0].numpy()
        return embeddings / np.linalg.norm(embeddings)

    @property
    def dimension(self) -> int:
        """
        Get the dimension of the DPR embeddings.

        Returns
        -------
        int
            Size of the embedding vectors (768 for base model)
        """
        return 768

    @property
    def collection_name(self) -> str:
        """
        Get the name of the Qdrant collection for DPR embeddings.

        Returns
        -------
        str
            Collection name for storing DPR embeddings
        """
        return "news_dpr"

================
File: embedders/minilm.py
================
"""
MiniLM Embedder Module

This module implements text embedding using the MiniLM model through Sentence-BERT.
MiniLM is a compact yet powerful language model that provides high-quality
multilingual embeddings while being computationally efficient.
"""

import numpy as np
from sentence_transformers import SentenceTransformer
from .base import BaseEmbedder


class MiniLMEmbedder(BaseEmbedder):
    """
    MiniLM-based text embedder.

    This embedder uses a pre-trained MiniLM model through Sentence-BERT to generate
    dense vector representations of text. It provides a good balance between
    performance and computational efficiency.

    Parameters
    ----------
    model_name : str, optional (default="sentence-transformers/all-MiniLM-L6-v2")
        The name or path of the pre-trained MiniLM model to use

    Attributes
    ----------
    model : SentenceTransformer
        The underlying MiniLM model
    """

    def __init__(self, model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
        """
        Initialize the MiniLM embedder.

        Parameters
        ----------
        model_name : str, optional
            Name or path of the pre-trained model to load
        """
        self.model = SentenceTransformer(model_name)

    def embed(self, text: str) -> np.ndarray:
        """
        Convert text to MiniLM embedding vector.

        Parameters
        ----------
        text : str
            Input text to be embedded

        Returns
        -------
        np.ndarray
            Normalized MiniLM embedding vector
        """
        return self.model.encode(text, normalize_embeddings=True)

    @property
    def dimension(self) -> int:
        """
        Get the dimension of the MiniLM embeddings.

        Returns
        -------
        int
            Size of the embedding vectors
        """
        return self.model.get_sentence_embedding_dimension()

    @property
    def collection_name(self) -> str:
        """
        Get the name of the Qdrant collection for MiniLM embeddings.

        Returns
        -------
        str
            Collection name for storing MiniLM embeddings
        """
        return "news_minilm"

================
File: embedders/sbert.py
================
"""
SBERT Embedder Module

This module implements sentence embeddings using Sentence-BERT (SBERT) models.
It specifically uses a Spanish-tuned model by default for better performance
with Spanish text.
"""

import numpy as np
from sentence_transformers import SentenceTransformer
from .base import BaseEmbedder


class SBERTEmbedder(BaseEmbedder):
    """
    Sentence-BERT (SBERT) based text embedder.

    This embedder uses a pre-trained SBERT model to generate dense vector
    representations of text. It's particularly well-suited for semantic
    similarity tasks and doesn't require fitting.

    Parameters
    ----------
    model_name : str, optional (default="hiiamsid/sentence_similarity_spanish_es")
        The name or path of the pre-trained SBERT model to use.
        Default is a Spanish-tuned model.

    Attributes
    ----------
    model : SentenceTransformer
        The underlying SBERT model
    """

    def __init__(self, model_name: str = "hiiamsid/sentence_similarity_spanish_es"):
        """
        Initialize the SBERT embedder.

        Parameters
        ----------
        model_name : str, optional
            Name or path of the pre-trained model to load
        """
        self.model = SentenceTransformer(model_name)

    def embed(self, text: str) -> np.ndarray:
        """
        Convert text to SBERT embedding vector.

        Parameters
        ----------
        text : str
            Input text to be embedded

        Returns
        -------
        np.ndarray
            Normalized SBERT embedding vector
        """
        return self.model.encode(text, normalize_embeddings=True)

    @property
    def dimension(self) -> int:
        """
        Get the dimension of the SBERT embeddings.

        Returns
        -------
        int
            Size of the embedding vectors
        """
        return self.model.get_sentence_embedding_dimension()

    @property
    def collection_name(self) -> str:
        """
        Get the name of the Qdrant collection for SBERT embeddings.

        Returns
        -------
        str
            Collection name for storing SBERT embeddings
        """
        return "news_sbert"

================
File: embedders/tfidf.py
================
"""
TF-IDF Embedder Module

This module implements the TF-IDF (Term Frequency-Inverse Document Frequency)
embedding approach. It uses scikit-learn's TfidfVectorizer to convert text
into fixed-size vector representations.
"""

from typing import List
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from .base import BaseEmbedder


class TfidfEmbedder(BaseEmbedder):
    """
    TF-IDF based text embedder.

    This embedder uses TF-IDF vectorization to convert text into numerical vectors.
    It requires fitting on a corpus before it can be used for embedding.

    Parameters
    ----------
    max_features : int, optional (default=384)
        Maximum number of features (terms) to include in the vocabulary

    Attributes
    ----------
    vectorizer : TfidfVectorizer
        The underlying scikit-learn TF-IDF vectorizer
    fitted : bool
        Indicates whether the vectorizer has been fitted to a corpus

    """

    def __init__(self, max_features: int = 384):
        """
        Initialize the TF-IDF embedder.

        Parameters
        ----------
        max_features : int, optional (default=384)
            Maximum number of features in the TF-IDF vocabulary
        """
        self.vectorizer = TfidfVectorizer(max_features=max_features)
        self.fitted = False

    def fit(self, texts: List[str]) -> None:
        """
        Fit the TF-IDF vectorizer on a corpus of texts.

        Parameters
        ----------
        texts : List[str]
            List of documents to learn the vocabulary from

        Returns
        -------
        None
        """
        self.vectorizer.fit(texts)
        self.fitted = True

    def embed(self, text: str) -> np.ndarray:
        """
        Convert text to TF-IDF vector representation.

        Parameters
        ----------
        text : str
            Input text to be embedded

        Returns
        -------
        np.ndarray
            TF-IDF vector representation of the input text

        Raises
        ------
        ValueError
            If the vectorizer hasn't been fitted yet
        """
        if not self.fitted:
            raise ValueError("TfidfVectorizer needs to be fitted first")
        vector = self.vectorizer.transform([text]).toarray()
        return vector[0]

    @property
    def dimension(self) -> int:
        """
        Get the dimension of the TF-IDF vectors.

        Returns
        -------
        int
            Number of features in the TF-IDF vocabulary
        """
        return self.vectorizer.max_features

    @property
    def collection_name(self) -> str:
        """
        Get the name of the Qdrant collection for TF-IDF embeddings.

        Returns
        -------
        str
            Collection name for storing TF-IDF embeddings
        """
        return "news_tfidf"

================
File: evaluation/test_sets/test_queries.json
================
[
  {
    "prompt": "noticias sobre pesquera china",
    "keywords": [],
    "date": "2024-12-10",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de pesquera china",
    "keywords": [],
    "date": "2024-12-15",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de pesquera china",
    "keywords": [],
    "date": "2024-12-14",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre pesquera china",
    "keywords": [],
    "date": "2024-12-12",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "pesquera china",
    "keywords": [],
    "date": "2024-12-16",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre apreciaci\u00f3n del peso",
    "keywords": [
      "d\u00f3lar"
    ],
    "date": "2024-12-12",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "d\u00f3lar"
    ],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de apreciaci\u00f3n del peso",
    "keywords": [
      "d\u00f3lar"
    ],
    "date": "2024-12-11",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "d\u00f3lar"
    ],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de apreciaci\u00f3n del peso",
    "keywords": [
      "d\u00f3lar"
    ],
    "date": "2024-12-10",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "d\u00f3lar"
    ],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre apreciaci\u00f3n del peso",
    "keywords": [
      "d\u00f3lar"
    ],
    "date": "2024-12-12",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "d\u00f3lar"
    ],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "apreciaci\u00f3n del peso",
    "keywords": [
      "d\u00f3lar"
    ],
    "date": "2024-12-11",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "d\u00f3lar"
    ],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre pymes caputo",
    "keywords": [],
    "date": "2024-12-13",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de pymes caputo",
    "keywords": [],
    "date": "2024-12-11",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de pymes caputo",
    "keywords": [],
    "date": "2024-12-12",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre pymes caputo",
    "keywords": [],
    "date": "2024-12-15",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "pymes caputo",
    "keywords": [],
    "date": "2024-12-12",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre transferencia de emisiones",
    "keywords": [],
    "date": "2024-12-15",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de transferencia de emisiones",
    "keywords": [],
    "date": "2024-12-14",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de transferencia de emisiones",
    "keywords": [],
    "date": "2024-12-13",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre transferencia de emisiones",
    "keywords": [],
    "date": "2024-12-11",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "transferencia de emisiones",
    "keywords": [],
    "date": "2024-12-14",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre d\u00f3lar MEP",
    "keywords": [
      "d\u00f3lar"
    ],
    "date": "2024-12-16",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "d\u00f3lar"
    ],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de d\u00f3lar MEP",
    "keywords": [
      "d\u00f3lar"
    ],
    "date": "2024-12-14",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "d\u00f3lar"
    ],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de d\u00f3lar MEP",
    "keywords": [
      "d\u00f3lar"
    ],
    "date": "2024-12-12",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "d\u00f3lar"
    ],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre d\u00f3lar MEP",
    "keywords": [
      "d\u00f3lar"
    ],
    "date": "2024-12-16",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "d\u00f3lar"
    ],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "d\u00f3lar MEP",
    "keywords": [
      "d\u00f3lar"
    ],
    "date": "2024-12-16",
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "d\u00f3lar"
    ],
    "date": null,
    "section": "Econom\u00eda",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre donald trump",
    "keywords": [
      "trump"
    ],
    "date": "2024-12-11",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "trump"
    ],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de donald trump",
    "keywords": [
      "trump"
    ],
    "date": "2024-12-12",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "trump"
    ],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de donald trump",
    "keywords": [
      "trump"
    ],
    "date": "2024-12-11",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "trump"
    ],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre donald trump",
    "keywords": [
      "trump"
    ],
    "date": "2024-12-15",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "trump"
    ],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "donald trump",
    "keywords": [
      "trump"
    ],
    "date": "2024-12-15",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "trump"
    ],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre seguridad social en estados unidos",
    "keywords": [],
    "date": "2024-12-16",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de seguridad social en estados unidos",
    "keywords": [],
    "date": "2024-12-11",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de seguridad social en estados unidos",
    "keywords": [],
    "date": "2024-12-13",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre seguridad social en estados unidos",
    "keywords": [],
    "date": "2024-12-11",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "seguridad social en estados unidos",
    "keywords": [],
    "date": "2024-12-16",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre cambio clim\u00e1tico",
    "keywords": [],
    "date": "2024-12-11",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de cambio clim\u00e1tico",
    "keywords": [],
    "date": "2024-12-14",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de cambio clim\u00e1tico",
    "keywords": [],
    "date": "2024-12-10",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre cambio clim\u00e1tico",
    "keywords": [],
    "date": "2024-12-14",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "cambio clim\u00e1tico",
    "keywords": [],
    "date": "2024-12-13",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre reloj de oro del titanic",
    "keywords": [],
    "date": "2024-12-13",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de reloj de oro del titanic",
    "keywords": [],
    "date": "2024-12-11",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de reloj de oro del titanic",
    "keywords": [],
    "date": "2024-12-15",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre reloj de oro del titanic",
    "keywords": [],
    "date": "2024-12-13",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "reloj de oro del titanic",
    "keywords": [],
    "date": "2024-12-16",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre g20 brasil",
    "keywords": [
      "brasil",
      "lula"
    ],
    "date": "2024-12-13",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "brasil",
      "lula"
    ],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de g20 brasil",
    "keywords": [
      "brasil",
      "lula"
    ],
    "date": "2024-12-15",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "brasil",
      "lula"
    ],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de g20 brasil",
    "keywords": [
      "brasil",
      "lula"
    ],
    "date": "2024-12-16",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "brasil",
      "lula"
    ],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre g20 brasil",
    "keywords": [
      "brasil",
      "lula"
    ],
    "date": "2024-12-14",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "brasil",
      "lula"
    ],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "g20 brasil",
    "keywords": [
      "brasil",
      "lula"
    ],
    "date": "2024-12-13",
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "brasil",
      "lula"
    ],
    "date": null,
    "section": "Internacional",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre congreso nacional",
    "keywords": [],
    "date": "2024-12-10",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de congreso nacional",
    "keywords": [],
    "date": "2024-12-11",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de congreso nacional",
    "keywords": [],
    "date": "2024-12-10",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre congreso nacional",
    "keywords": [],
    "date": "2024-12-16",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "congreso nacional",
    "keywords": [],
    "date": "2024-12-10",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre Emanuel Macron",
    "keywords": [
      "francia",
      "presidente"
    ],
    "date": "2024-12-11",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "francia",
      "presidente"
    ],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de Emanuel Macron",
    "keywords": [
      "francia",
      "presidente"
    ],
    "date": "2024-12-16",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "francia",
      "presidente"
    ],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de Emanuel Macron",
    "keywords": [
      "francia",
      "presidente"
    ],
    "date": "2024-12-13",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "francia",
      "presidente"
    ],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre Emanuel Macron",
    "keywords": [
      "francia",
      "presidente"
    ],
    "date": "2024-12-11",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "francia",
      "presidente"
    ],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "Emanuel Macron",
    "keywords": [
      "francia",
      "presidente"
    ],
    "date": "2024-12-12",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "francia",
      "presidente"
    ],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre kirchnerismo",
    "keywords": [
      "kirchner"
    ],
    "date": "2024-12-12",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "kirchner"
    ],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de kirchnerismo",
    "keywords": [
      "kirchner"
    ],
    "date": "2024-12-10",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "kirchner"
    ],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de kirchnerismo",
    "keywords": [
      "kirchner"
    ],
    "date": "2024-12-10",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "kirchner"
    ],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre kirchnerismo",
    "keywords": [
      "kirchner"
    ],
    "date": "2024-12-12",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "kirchner"
    ],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "kirchnerismo",
    "keywords": [
      "kirchner"
    ],
    "date": "2024-12-12",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "kirchner"
    ],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre Estados Unidos",
    "keywords": [],
    "date": "2024-12-11",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de Estados Unidos",
    "keywords": [],
    "date": "2024-12-11",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de Estados Unidos",
    "keywords": [],
    "date": "2024-12-15",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre Estados Unidos",
    "keywords": [],
    "date": "2024-12-15",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "Estados Unidos",
    "keywords": [],
    "date": "2024-12-15",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre Cristina Kirchner",
    "keywords": [
      "kirchner",
      "senado"
    ],
    "date": "2024-12-11",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "kirchner",
      "senado"
    ],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de Cristina Kirchner",
    "keywords": [
      "kirchner",
      "senado"
    ],
    "date": "2024-12-11",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "kirchner",
      "senado"
    ],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de Cristina Kirchner",
    "keywords": [
      "kirchner",
      "senado"
    ],
    "date": "2024-12-15",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "kirchner",
      "senado"
    ],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre Cristina Kirchner",
    "keywords": [
      "kirchner",
      "senado"
    ],
    "date": "2024-12-15",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "kirchner",
      "senado"
    ],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "Cristina Kirchner",
    "keywords": [
      "kirchner",
      "senado"
    ],
    "date": "2024-12-10",
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "kirchner",
      "senado"
    ],
    "date": null,
    "section": "Pol\u00edtica",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre Efem\u00e9rides",
    "keywords": [
      "historia"
    ],
    "date": "2024-12-16",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "historia"
    ],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de Efem\u00e9rides",
    "keywords": [
      "historia"
    ],
    "date": "2024-12-16",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "historia"
    ],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de Efem\u00e9rides",
    "keywords": [
      "historia"
    ],
    "date": "2024-12-12",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "historia"
    ],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre Efem\u00e9rides",
    "keywords": [
      "historia"
    ],
    "date": "2024-12-10",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "historia"
    ],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "Efem\u00e9rides",
    "keywords": [
      "historia"
    ],
    "date": "2024-12-14",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "historia"
    ],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre clima",
    "keywords": [],
    "date": "2024-12-11",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de clima",
    "keywords": [],
    "date": "2024-12-13",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de clima",
    "keywords": [],
    "date": "2024-12-11",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre clima",
    "keywords": [],
    "date": "2024-12-15",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "clima",
    "keywords": [],
    "date": "2024-12-13",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre hormigas voladoras",
    "keywords": [],
    "date": "2024-12-13",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de hormigas voladoras",
    "keywords": [],
    "date": "2024-12-12",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de hormigas voladoras",
    "keywords": [],
    "date": "2024-12-14",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre hormigas voladoras",
    "keywords": [],
    "date": "2024-12-10",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "hormigas voladoras",
    "keywords": [],
    "date": "2024-12-14",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre Lionsgate",
    "keywords": [
      "cine",
      "pel\u00edcula"
    ],
    "date": "2024-12-15",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "cine",
      "pel\u00edcula"
    ],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de Lionsgate",
    "keywords": [
      "cine",
      "pel\u00edcula"
    ],
    "date": "2024-12-14",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "cine",
      "pel\u00edcula"
    ],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de Lionsgate",
    "keywords": [
      "cine",
      "pel\u00edcula"
    ],
    "date": "2024-12-13",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "cine",
      "pel\u00edcula"
    ],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre Lionsgate",
    "keywords": [
      "cine",
      "pel\u00edcula"
    ],
    "date": "2024-12-11",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "cine",
      "pel\u00edcula"
    ],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "Lionsgate",
    "keywords": [
      "cine",
      "pel\u00edcula"
    ],
    "date": "2024-12-16",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "cine",
      "pel\u00edcula"
    ],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre Andrea Giunta",
    "keywords": [],
    "date": "2024-12-16",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de Andrea Giunta",
    "keywords": [],
    "date": "2024-12-16",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de Andrea Giunta",
    "keywords": [],
    "date": "2024-12-12",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre Andrea Giunta",
    "keywords": [],
    "date": "2024-12-16",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "Andrea Giunta",
    "keywords": [],
    "date": "2024-12-16",
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": "Sociedad",
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre crisis econ\u00f3mica",
    "keywords": [],
    "date": "2024-12-14",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de crisis econ\u00f3mica",
    "keywords": [],
    "date": "2024-12-11",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de crisis econ\u00f3mica",
    "keywords": [],
    "date": "2024-12-15",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre crisis econ\u00f3mica",
    "keywords": [],
    "date": "2024-12-11",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": "crisis econ\u00f3mica",
    "keywords": [],
    "date": "2024-12-11",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre presupuesto nacional",
    "keywords": [],
    "date": "2024-12-15",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de presupuesto nacional",
    "keywords": [],
    "date": "2024-12-15",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de presupuesto nacional",
    "keywords": [],
    "date": "2024-12-12",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre presupuesto nacional",
    "keywords": [],
    "date": "2024-12-16",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": "presupuesto nacional",
    "keywords": [],
    "date": "2024-12-15",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre pol\u00edticas p\u00fablicas",
    "keywords": [
      "gobierno"
    ],
    "date": "2024-12-10",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "gobierno"
    ],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de pol\u00edticas p\u00fablicas",
    "keywords": [
      "gobierno"
    ],
    "date": "2024-12-12",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "gobierno"
    ],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de pol\u00edticas p\u00fablicas",
    "keywords": [
      "gobierno"
    ],
    "date": "2024-12-12",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "gobierno"
    ],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre pol\u00edticas p\u00fablicas",
    "keywords": [
      "gobierno"
    ],
    "date": "2024-12-12",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "gobierno"
    ],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": "pol\u00edticas p\u00fablicas",
    "keywords": [
      "gobierno"
    ],
    "date": "2024-12-12",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "gobierno"
    ],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": "noticias sobre impacto social",
    "keywords": [
      "social"
    ],
    "date": "2024-12-15",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "social"
    ],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": "informaci\u00f3n de impacto social",
    "keywords": [
      "social"
    ],
    "date": "2024-12-16",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "social"
    ],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": "\u00faltimas noticias de impacto social",
    "keywords": [
      "social"
    ],
    "date": "2024-12-10",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "social"
    ],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": "actualidad sobre impacto social",
    "keywords": [
      "social"
    ],
    "date": "2024-12-11",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "social"
    ],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": "impacto social",
    "keywords": [
      "social"
    ],
    "date": "2024-12-14",
    "section": null,
    "min_keyword_score": 0.1
  },
  {
    "prompt": null,
    "keywords": [
      "social"
    ],
    "date": null,
    "section": null,
    "min_keyword_score": 0.1
  }
]

================
File: evaluation/test_sets/test_set_summary.json
================
{
  "total_queries": 240,
  "by_section": {
    "Econom\u00eda": 50,
    "Internacional": 50,
    "Pol\u00edtica": 50,
    "Sociedad": 50
  },
  "query_types": {
    "semantic_only": 65,
    "keyword_only": 55,
    "combined": 55
  },
  "with_date": 120,
  "with_section": 200,
  "cross_section": 40
}

================
File: evaluation/metrics.py
================
"""
Evaluation Metrics Module

This module provides functionality for evaluating the performance of different
embedding and retrieval strategies for the news article RAG system.
"""

from typing import List, Dict, Any, Optional, Set, Tuple
from dataclasses import dataclass
from datetime import datetime
import time
import numpy as np
from sklearn.metrics import ndcg_score
from storage.qdrant_manager import QdrantManager


@dataclass
class SearchQuery:
    """Data class representing a search query with optional filters."""
    prompt: str
    date: Optional[str] = None
    section: Optional[str] = None
    keywords: Optional[List[str]] = None
    min_keyword_score: float = 0.0


@dataclass
class SearchResult:
    """Data class representing search results and metrics."""
    query: SearchQuery
    results: List[Dict]
    execution_time: float


@dataclass
class EvaluationMetrics:
    """Data class containing evaluation metrics for a search strategy."""
    precision: float
    recall: float
    ndcg: float
    keyword_precision: float
    keyword_recall: float
    keyword_f1: float
    mean_execution_time: float
    queries_per_second: float


class RAGEvaluator:
    """Class for evaluating RAG system performance across different scenarios."""

    def __init__(self, embedder, local: bool = True):
        """
        Initialize the RAG evaluator.

        Parameters
        ----------
        embedder : BaseEmbedder
            The embedder to use for evaluation
        local : bool
            Whether to use local Qdrant instance
        """
        self.embedder = embedder
        self.qdrant = QdrantManager(local=local)
        self.collection_name = embedder.collection_name

    def execute_search(self, query: SearchQuery, limit: int = 5) -> SearchResult:
        """
        Execute a search query and measure execution time.

        Parameters
        ----------
        query : SearchQuery
            The search query to execute
        limit : int, optional
            Maximum number of results to retrieve

        Returns
        -------
        SearchResult
            Search results and execution metrics
        """
        start_time = time.time()

        # Prepare filter conditions
        filter_conditions = {}
        if query.date:
            filter_conditions['date'] = query.date
        if query.section:
            filter_conditions['section'] = query.section

        # Execute appropriate search based on query type
        if query.prompt and query.keywords:
            # Combined semantic and keyword search
            query_vector = self.embedder.embed(query.prompt)
            results = self.qdrant.search(
                collection_name=self.collection_name,
                query_vector=query_vector,
                filter_conditions=filter_conditions,
                keywords=query.keywords,
                min_keyword_score=query.min_keyword_score,
                limit=limit
            )
        elif query.prompt:
            # Semantic search only
            query_vector = self.embedder.embed(query.prompt)
            results = self.qdrant.search(
                collection_name=self.collection_name,
                query_vector=query_vector,
                filter_conditions=filter_conditions,
                limit=limit
            )
        else:
            # Keyword search only
            results = self.qdrant.search_by_keywords(
                collection_name=self.collection_name,
                keywords=query.keywords,
                min_keyword_score=query.min_keyword_score,
                filter_conditions=filter_conditions,
                limit=limit
            )

        execution_time = time.time() - start_time

        return SearchResult(query=query, results=results, execution_time=execution_time)

    def calculate_keyword_metrics(
        self,
        retrieved_keywords: Set[str],
        relevant_keywords: Set[str]
    ) -> Tuple[float, float, float]:
        """
        Calculate precision, recall, and F1 score for keyword retrieval.

        Parameters
        ----------
        retrieved_keywords : Set[str]
            Set of keywords retrieved by the search
        relevant_keywords : Set[str]
            Set of relevant keywords for the query

        Returns
        -------
        Tuple[float, float, float]
            Precision, recall, and F1 scores
        """
        if not relevant_keywords:
            return 0.0, 0.0, 0.0

        intersection = len(retrieved_keywords & relevant_keywords)
        precision = intersection / len(retrieved_keywords) if retrieved_keywords else 0
        recall = intersection / len(relevant_keywords)
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

        return precision, recall, f1

    def evaluate_queries(
        self,
        queries: List[SearchQuery],
        relevant_docs: Dict[str, Dict[str, Any]],
        k: int = 5
    ) -> EvaluationMetrics:
        """
        Evaluate a list of queries and compute metrics.

        Parameters
        ----------
        queries : List[SearchQuery]
            List of queries to evaluate
        relevant_docs : Dict[str, Dict[str, Any]]
            Dictionary mapping query prompts to relevant document info
        k : int, optional
            Number of results to consider for metrics

        Returns
        -------
        EvaluationMetrics
            Computed evaluation metrics
        """
        execution_times = []
        precision_scores = []
        recall_scores = []
        ndcg_scores = []
        keyword_precision_scores = []
        keyword_recall_scores = []
        keyword_f1_scores = []

        for query in queries:
            # Execute search
            result = self.execute_search(query, limit=k)
            execution_times.append(result.execution_time)

            # Get relevant info for this query
            relevant_info = relevant_docs.get(query.prompt or '', {})
            relevant_ids = set(relevant_info.get('doc_ids', []))
            relevant_keywords = set(relevant_info.get('keywords', []))

            # Get retrieved info
            retrieved_ids = {str(r['original_id']) for r in result.results}
            retrieved_keywords = {kw for r in result.results for kw, _ in r['keywords']}

            # Calculate document-level metrics
            intersection = len(retrieved_ids & relevant_ids)
            precision = intersection / len(retrieved_ids) if retrieved_ids else 0
            recall = intersection / len(relevant_ids) if relevant_ids else 0

            precision_scores.append(precision)
            recall_scores.append(recall)

            # Calculate NDCG
            relevance_scores = [1 if str(r['original_id']) in relevant_ids else 0 for r in result.results]
            ideal_scores = [1] * len(relevant_ids) + [0] * (k - len(relevant_ids))

            try:
                ndcg = ndcg_score([ideal_scores], [relevance_scores])
            except ValueError:
                ndcg = 0.0

            ndcg_scores.append(ndcg)

            # Calculate keyword metrics
            kw_precision, kw_recall, kw_f1 = self.calculate_keyword_metrics(
                retrieved_keywords,
                relevant_keywords
            )
            keyword_precision_scores.append(kw_precision)
            keyword_recall_scores.append(kw_recall)
            keyword_f1_scores.append(kw_f1)

        # Calculate mean metrics
        mean_execution_time = np.mean(execution_times)

        return EvaluationMetrics(
            precision=np.mean(precision_scores),
            recall=np.mean(recall_scores),
            ndcg=np.mean(ndcg_scores),
            keyword_precision=np.mean(keyword_precision_scores),
            keyword_recall=np.mean(keyword_recall_scores),
            keyword_f1=np.mean(keyword_f1_scores),
            mean_execution_time=mean_execution_time,
            queries_per_second=1.0 / mean_execution_time if mean_execution_time > 0 else 0.0
        )

    def generate_evaluation_report(
        self,
        test_queries: List[SearchQuery],
        relevant_docs: Dict[str, Dict[str, Any]],
        k: int = 5
    ) -> Dict[str, Any]:
        """
        Generate a comprehensive evaluation report.

        Parameters
        ----------
        test_queries : List[SearchQuery]
            List of queries to evaluate
        relevant_docs : Dict[str, Dict[str, Any]]
            Dictionary of relevant documents for each query
        k : int, optional
            Number of results to consider

        Returns
        -------
        Dict[str, Any]
            Evaluation report with metrics and statistics
        """
        metrics = self.evaluate_queries(test_queries, relevant_docs, k)

        report = {
            'embedder_type': self.embedder.__class__.__name__.replace('Embedder', '').lower(),
            'collection_name': self.collection_name,
            'number_of_queries': len(test_queries),
            'k': k,
            'metrics': {
                'precision_at_k': metrics.precision,
                'recall_at_k': metrics.recall,
                'ndcg': metrics.ndcg,
                'keyword_precision': metrics.keyword_precision,
                'keyword_recall': metrics.keyword_recall,
                'keyword_f1': metrics.keyword_f1,
                'mean_execution_time': metrics.mean_execution_time,
                'queries_per_second': metrics.queries_per_second
            },
            'query_categories': {
                'semantic_only': len([q for q in test_queries if q.prompt and not q.keywords]),
                'keyword_only': len([q for q in test_queries if q.keywords and not q.prompt]),
                'combined': len([q for q in test_queries if q.prompt and q.keywords]),
                'with_date': len([q for q in test_queries if q.date]),
                'with_section': len([q for q in test_queries if q.section])
            },
            'timestamp': datetime.now().isoformat()
        }

        return report

================
File: evaluation/visualization.py
================
"""
Visualization Utilities for RAG Evaluation Results

This module provides functions for visualizing and comparing the performance
of different embedding strategies using various metrics and charts.
"""

from typing import List, Dict, Any
import json
from pathlib import Path
import pandas as pd
import plotly.graph_objs as go
import plotly.express as px
from plotly.subplots import make_subplots


class ResultsVisualizer:
    """Class for creating visualizations of RAG evaluation results."""

    def __init__(self, results_dir: str):
        """Initialize the visualizer with results directory."""
        self.results_dir = Path(results_dir)
        self.embedders = []
        self.results = {}
        self._load_results()

    def _load_results(self):
        """Load all JSON result files from the results directory."""
        for file_path in self.results_dir.glob('*_report.json'):
            embedder = file_path.stem.replace('_report', '')
            with open(file_path) as f:
                self.results[embedder] = json.load(f)
                if embedder not in self.embedders:
                    self.embedders.append(embedder)

    def create_metrics_comparison(self) -> go.Figure:
        """Create a bar chart comparing key metrics across embedders."""
        df_metrics = []

        for embedder, data in self.results.items():
            metrics = data['metrics']
            df_metrics.append({
                'Embedder': embedder,
                'Semantic Precision': metrics['precision_at_k'],
                'Semantic Recall': metrics['recall_at_k'],
                'NDCG': metrics['ndcg'],
                'Keyword Precision': metrics['keyword_precision'],
                'Keyword Recall': metrics['keyword_recall'],
                'Keyword F1': metrics['keyword_f1'],
                'QPS': metrics['queries_per_second']
            })

        df = pd.DataFrame(df_metrics)

        fig = make_subplots(
            rows=3, cols=1,
            subplot_titles=(
                'Semantic Retrieval Metrics',
                'Keyword-based Metrics',
                'Performance (Queries/Second)'
            ),
            vertical_spacing=0.2,
            row_heights=[0.4, 0.4, 0.2]
        )

        # Semantic metrics
        for metric in ['Semantic Precision', 'Semantic Recall', 'NDCG']:
            fig.add_trace(
                go.Bar(
                    name=metric,
                    x=df['Embedder'],
                    y=df[metric],
                    text=df[metric].round(3),
                    textposition='auto',
                ),
                row=1, col=1
            )

        # Keyword metrics
        for metric in ['Keyword Precision', 'Keyword Recall', 'Keyword F1']:
            fig.add_trace(
                go.Bar(
                    name=metric,
                    x=df['Embedder'],
                    y=df[metric],
                    text=df[metric].round(3),
                    textposition='auto',
                ),
                row=2, col=1
            )

        # Performance metric
        fig.add_trace(
            go.Bar(
                name='QPS',
                x=df['Embedder'],
                y=df['QPS'],
                text=df['QPS'].round(2),
                textposition='auto',
            ),
            row=3, col=1
        )

        fig.update_layout(
            title_text='Embedding Strategies Comparison',
            height=1000,
            showlegend=True,
            barmode='group'
        )

        return fig

    def create_query_type_performance(self) -> go.Figure:
        """Create a heatmap showing performance across different query types."""
        performance_data = []

        for embedder, data in self.results.items():
            metrics = data['metrics']
            performance_data.append({
                'Embedder': embedder,
                'Semantic Only': metrics['precision_at_k'],
                'Keyword Only': metrics['keyword_precision'],
                'Combined': (metrics['precision_at_k'] + metrics['keyword_precision']) / 2,
            })

        df = pd.DataFrame(performance_data)

        fig = go.Figure(data=go.Heatmap(
            z=df[['Semantic Only', 'Keyword Only', 'Combined']].values,
            x=['Semantic Only', 'Keyword Only', 'Combined'],
            y=df['Embedder'],
            text=df[['Semantic Only', 'Keyword Only', 'Combined']].round(3).values,
            texttemplate='%{text}',
            textfont={"size": 10},
            hoverongaps=False,
            colorscale='RdYlGn'
        ))

        fig.update_layout(
            title='Query Type Performance by Embedder',
            xaxis_title='Query Type',
            yaxis_title='Embedder'
        )

        return fig

    def create_execution_time_plot(self) -> go.Figure:
        """Create a box plot of execution times by query type."""
        exec_times = []
        mean_times = []

        for embedder, data in self.results.items():
            if 'execution_times' in data:
                for query_type, times in data['execution_times'].items():
                    for time in times:
                        exec_times.append({
                            'Embedder': embedder,
                            'Query Type': query_type,
                            'Time (s)': time
                        })
            else:
                # Use mean execution time if detailed timing data not available
                mean_times.append({
                    'Embedder': embedder,
                    'Time (s)': data['metrics']['mean_execution_time']
                })

        if exec_times:
            df = pd.DataFrame(exec_times)
            fig = px.box(
                df,
                x='Embedder',
                y='Time (s)',
                color='Query Type',
                title='Query Execution Time Distribution by Query Type'
            )
        else:
            df = pd.DataFrame(mean_times)
            fig = px.bar(
                df,
                x='Embedder',
                y='Time (s)',
                title='Mean Query Execution Time'
            )

        return fig

    def generate_report(self, output_dir: str):
        """Generate a complete HTML report with all visualizations."""
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)

        # Create all visualizations
        metrics_fig = self.create_metrics_comparison()
        query_type_fig = self.create_query_type_performance()
        time_fig = self.create_execution_time_plot()

        # Combine into HTML report
        html_content = f"""
        <html>
        <head>
            <title>RAG Evaluation Results</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .chart {{ margin: 20px 0; padding: 20px; border: 1px solid #ddd; }}
                .description {{ color: #666; margin: 10px 0; }}
            </style>
        </head>
        <body>
            <h1>RAG Evaluation Results</h1>

            <div class="chart">
                <h2>Overall Performance Metrics</h2>
                <div class="description">
                    Comparison of semantic and keyword-based retrieval performance
                    across different embedding strategies.
                </div>
                {metrics_fig.to_html(full_html=False)}
            </div>

            <div class="chart">
                <h2>Query Type Performance</h2>
                <div class="description">
                    Performance comparison across different types of queries:
                    semantic-only, keyword-only, and combined approaches.
                </div>
                {query_type_fig.to_html(full_html=False)}
            </div>

            <div class="chart">
                <h2>Execution Time Analysis</h2>
                <div class="description">
                    Query execution time distribution by embedder and query type.
                </div>
                {time_fig.to_html(full_html=False)}
            </div>

            <footer>
                <p>Generated on: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            </footer>
        </body>
        </html>
        """

        with open(output_path / 'evaluation_report.html', 'w', encoding='utf-8') as f:
            f.write(html_content)

        # Save individual figures
        metrics_fig.write_image(output_path / 'metrics_comparison.png')
        query_type_fig.write_image(output_path / 'query_type_performance.png')
        time_fig.write_image(output_path / 'execution_time.png')

================
File: scripts/utils/common.py
================
"""
Common utility functions shared across scripts.

This module provides common functionality used by multiple scripts,
including configuration loading and client initialization.
"""

import os
from pathlib import Path
from typing import Dict, Any, Optional
import yaml
from qdrant_client import QdrantClient
from qdrant_client.http.exceptions import UnexpectedResponse


def load_config() -> Dict[str, Any]:
    """
    Load configuration from YAML file.

    Returns
    -------
    Dict[str, Any]
        Configuration dictionary

    Raises
    ------
    FileNotFoundError
        If config file doesn't exist
    """
    config_path = Path(__file__).parent.parent.parent / "config" / "config.yaml"

    if not config_path.exists():
        raise FileNotFoundError(f"Configuration file not found at {config_path}")

    with open(config_path) as f:
        config = yaml.safe_load(f)

    # Replace environment variables in the config
    if '${DATABASE_URL}' in config.get('database', {}).get('url', ''):
        config['database']['url'] = os.getenv('DATABASE_URL')

    if '${QDRANT_API_KEY}' in config.get('qdrant', {}).get('cloud', {}).get('api_key', ''):
        config['qdrant']['cloud']['api_key'] = os.getenv('QDRANT_API_KEY')

    return config


def get_qdrant_client(local: bool = True) -> QdrantClient:
    """
    Initialize Qdrant client based on configuration.

    Parameters
    ----------
    local : bool
        Whether to use local or cloud instance

    Returns
    -------
    QdrantClient
        Initialized Qdrant client

    Raises
    ------
    ValueError
        If cloud configuration is missing required parameters
    """
    config = load_config()

    if local:
        local_config = config['qdrant']['local']
        return QdrantClient(
            host=local_config['host'],
            port=local_config['port']
        )
    else:
        cloud_config = config['qdrant']['cloud']
        if not os.getenv('QDRANT_API_KEY'):
            raise ValueError("QDRANT_API_KEY environment variable not set")

        return QdrantClient(
            url=cloud_config['url'],
            api_key=os.getenv('QDRANT_API_KEY')
        )


def get_embedder(embedder_type: str, config: dict, articles: Optional[list] = None):
    """
    Get the appropriate embedder instance and fit if necessary.

    Parameters
    ----------
    embedder_type : str
        Type of embedder to create
    config : dict
        Configuration dictionary
    articles : Optional[list]
        Articles to fit the embedder on (for TF-IDF and BM25)

    Returns
    -------
    BaseEmbedder
        Initialized embedder instance
    """
    from embedders import (
        TfidfEmbedder,
        SBERTEmbedder,
        DPREmbedder,
        MiniLMEmbedder,
        BM25Embedder
    )

    embedder_config = config['embedders'].get(embedder_type, {})

    if embedder_type == 'tfidf':
        embedder = TfidfEmbedder(max_features=embedder_config.get('max_features', 384))
        if articles:
            print(f"Fitting {embedder_type} embedder on {len(articles)} articles...")
            embedder.fit([article['content'] for article in articles])
    elif embedder_type == 'bm25':
        embedder = BM25Embedder()
        if articles:
            print(f"Fitting {embedder_type} embedder on {len(articles)} articles...")
            embedder.fit([article['content'] for article in articles])
    elif embedder_type == 'sbert':
        embedder = SBERTEmbedder(model_name=embedder_config['model_name'])
    elif embedder_type == 'dpr':
        embedder = DPREmbedder(model_name=embedder_config['model_name'])
    elif embedder_type == 'minilm':
        embedder = MiniLMEmbedder(model_name=embedder_config['model_name'])
    else:
        raise ValueError(f"Invalid embedder type: {embedder_type}")

    return embedder

================
File: scripts/utils/logging_config.py
================
import logging
import sys
from datetime import datetime


def setup_logging(name: str, level: str = "INFO") -> logging.Logger:
    """Set up logging configuration."""
    # Create logger
    logger = logging.getLogger(name)
    logger.setLevel(getattr(logging, level))

    # Create console handler with formatting
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(getattr(logging, level))

    # Create file handler with formatting
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    file_handler = logging.FileHandler(f"logs/{name}_{timestamp}.log")
    file_handler.setLevel(getattr(logging, level))

    # Create formatter
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    console_handler.setFormatter(formatter)
    file_handler.setFormatter(formatter)

    # Add handlers to logger
    logger.addHandler(console_handler)
    logger.addHandler(file_handler)

    return logger

================
File: scripts/evaluate_embeddings.py
================
"""
Embedding Evaluation Script

This script evaluates different embedding strategies using various types
of queries and generates comparative metrics including keyword-based evaluation.
"""

import argparse
import json
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional, Set
import pandas as pd
from dotenv import load_dotenv
from config import SessionLocal
from storage.data_loader import load_articles_from_db
from evaluation.metrics import RAGEvaluator, SearchQuery
from utils.logging_config import setup_logging
from utils.common import (
    load_config,
    get_embedder
)

# Set up logger
logger = setup_logging("evaluator")


def load_test_queries() -> List[SearchQuery]:
    """
    Load test queries from the test set file.

    Returns
    -------
    List[SearchQuery]
        List of search queries for evaluation
    """
    test_queries_path = Path(__file__).parent.parent / "evaluation" / "test_sets" / "test_queries.json"

    if not test_queries_path.exists():
        raise FileNotFoundError(f"Test queries file not found at {test_queries_path}")

    try:
        with open(test_queries_path) as f:
            queries_data = json.load(f)

        return [
            SearchQuery(
                prompt=q.get('prompt'),
                date=q.get('date'),
                section=q.get('section'),
                keywords=q.get('keywords', []),
                min_keyword_score=q.get('min_keyword_score', 0.0)
            )
            for q in queries_data
        ]
    except Exception as e:
        logger.error(f"Error loading test queries: {str(e)}")
        raise


def get_relevant_documents(
    queries: List[SearchQuery],
    articles: List[Dict],
    keyword_match_threshold: float = 0.5
) -> Dict[str, Dict]:
    """
    Get relevant documents and keywords for each query.

    Parameters
    ----------
    queries : List[SearchQuery]
        List of queries to evaluate
    articles : List[Dict]
        List of all available articles
    keyword_match_threshold : float
        Threshold for considering a keyword match relevant

    Returns
    -------
    Dict[str, Dict]
        Mapping of query prompts to dictionaries containing:
        - doc_ids: List of relevant document IDs
        - keywords: List of relevant keywords
    """
    relevant_docs = {}

    for query in queries:
        relevant = []
        all_keywords = set()

        # Get search terms from prompt
        search_terms = query.prompt.lower().split() if query.prompt else []
        query_keywords = set(query.keywords) if query.keywords else set()

        for article in articles:
            content = article['content'].lower()
            title = article['title'].lower()
            is_relevant = False

            # Check content/title relevance
            if search_terms and any(term in title or term in content for term in search_terms):
                is_relevant = True

            # Check keyword relevance
            article_keywords = {kw for kw, score in article['keywords'] if score >= keyword_match_threshold}
            if query_keywords and article_keywords & query_keywords:
                is_relevant = True

            # Apply filters
            if query.section and article['section'] != query.section:
                is_relevant = False

            if query.date:
                article_date = article['published_at'].strftime('%Y-%m-%d')
                if article_date != query.date:
                    is_relevant = False

            if is_relevant:
                relevant.append(str(article['id']))
                all_keywords.update(article_keywords)

        relevant_docs[query.prompt or ''] = {
            'doc_ids': relevant,
            'keywords': list(all_keywords)
        }

    return relevant_docs


def save_results(results: List[Dict], output_dir: Path):
    """
    Save evaluation results and generate comparative analysis.

    Parameters
    ----------
    results : List[Dict]
        List of evaluation results per embedder
    output_dir : Path
        Directory to save results
    """
    output_dir.mkdir(exist_ok=True)

    # Save individual reports
    for report in results:
        embedder_type = report['embedder_type']
        report_path = output_dir / f"{embedder_type}_report.json"
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)

    # Generate comparative analysis
    df = pd.DataFrame([
        {
            'Embedder': r['embedder_type'],
            'Precision@5': r['metrics']['precision_at_k'],
            'Recall@5': r['metrics']['recall_at_k'],
            'NDCG': r['metrics']['ndcg'],
            'Keyword Precision': r['metrics']['keyword_precision'],
            'Keyword Recall': r['metrics']['keyword_recall'],
            'Keyword F1': r['metrics']['keyword_f1'],
            'Queries/Second': r['metrics']['queries_per_second']
        }
        for r in results
    ])

    # Save comparison
    comparison_path = output_dir / "comparison.csv"
    df.to_csv(comparison_path, index=False)

    # Print summary
    logger.info("\nEvaluation Results Summary:")
    print(df.to_string(index=False))


def main():
    parser = argparse.ArgumentParser(description='Evaluate embedding strategies')
    parser.add_argument('--local', action='store_true',
                        help='Use local Qdrant instance')
    parser.add_argument('--output', type=str, default='evaluation_results',
                        help='Output directory for results')
    parser.add_argument('--embedders', nargs='+',
                        default=['tfidf', 'bm25', 'dpr', 'sbert', 'minilm'],
                        help='Embedder types to evaluate')
    parser.add_argument('--keyword-match-threshold', type=float, default=0.5,
                        help='Threshold for keyword relevance matching')
    parser.add_argument('--min-keyword-score', type=float, default=0.0,
                        help='Minimum score for including keywords in evaluation')

    args = parser.parse_args()

    try:
        # Load environment variables and configuration
        load_dotenv()
        config = load_config()

        # Initialize database connection
        logger.info("Connecting to database...")
        session = SessionLocal()

        try:
            # Load articles
            logger.info("Loading articles from database...")
            articles = load_articles_from_db(
                session,
                min_words=config['processing']['min_words'],
                max_words=config['processing']['max_words'],
                min_keyword_score=args.min_keyword_score
            )

            if not articles:
                logger.error("No articles found in database!")
                return

            logger.info(f"Loaded {len(articles)} articles")

            # Load test queries
            logger.info("Loading test queries...")
            test_queries = load_test_queries()

            if not test_queries:
                logger.error("No test queries found!")
                return

            logger.info(f"Loaded {len(test_queries)} test queries")

            # Log query distribution
            keyword_queries = len([q for q in test_queries if q.keywords])
            semantic_queries = len([q for q in test_queries if q.prompt])
            combined_queries = len([q for q in test_queries if q.prompt and q.keywords])

            logger.info("\nQuery Distribution:")
            logger.info(f"Semantic-only queries: {semantic_queries - combined_queries}")
            logger.info(f"Keyword-only queries: {keyword_queries - combined_queries}")
            logger.info(f"Combined queries: {combined_queries}")

            # Get relevant documents for evaluation
            logger.info("Getting relevant documents...")
            relevant_docs = get_relevant_documents(
                test_queries,
                articles,
                keyword_match_threshold=args.keyword_match_threshold
            )

            # Evaluate each embedding strategy
            results = []
            for embedder_type in args.embedders:
                logger.info(f"\nEvaluating {embedder_type}...")

                # Initialize and fit embedder if necessary
                embedder = get_embedder(embedder_type, config, articles)

                # Create evaluator
                evaluator = RAGEvaluator(embedder, local=args.local)

                # Generate evaluation report
                report = evaluator.generate_evaluation_report(
                    test_queries,
                    relevant_docs
                )

                results.append(report)

            # Save results
            logger.info("\nSaving results...")
            save_results(results, Path(args.output))

        finally:
            session.close()

    except Exception as e:
        logger.error(f"An error occurred: {str(e)}", exc_info=True)
        raise


if __name__ == "__main__":
    main()

================
File: scripts/generate_test_set.py
================
"""
Test Set Generator

This script provides utilities for generating test queries and identifying
relevant documents for RAG system evaluation, with section-specific topics
and keyword-based test cases.
"""

from typing import List, Dict, Set, Optional, Tuple
from datetime import datetime, timedelta
import random
import json
from pathlib import Path
from sqlalchemy import select, and_, or_
from sqlalchemy.orm import Session

from evaluation.metrics import SearchQuery
from models.db_models import Article, ProcessedArticle, Section
from storage.data_loader import parse_keywords

# Define section-specific topics with associated keywords
SECTION_TOPICS = {
    "Economa": [
        {
            "topic": "apreciacin del peso",
            "keywords": ["peso", "dlar", "tipo de cambio", "mercado cambiario"]
        },
        {
            "topic": "dlar MEP",
            "keywords": ["dlar", "mep", "bolsa", "bonos"]
        },
        {
            "topic": "pesquera china",
            "keywords": ["pesca", "china", "mar", "buques"]
        },
        {
            "topic": "pymes caputo",
            "keywords": ["pymes", "caputo", "empresas", "impuestos"]
        },
        {
            "topic": "transferencia de emisiones",
            "keywords": ["emisiones", "carbono", "clima", "ambiente"]
        }
    ],
    "Internacional": [
        {
            "topic": "cambio climtico",
            "keywords": ["clima", "calentamiento", "emisiones", "ambiente"]
        },
        {
            "topic": "reloj de oro del titanic",
            "keywords": ["titanic", "reloj", "subasta", "naufragio"]
        },
        {
            "topic": "seguridad social en estados unidos",
            "keywords": ["seguridad social", "eeuu", "pensiones", "jubilacin"]
        },
        {
            "topic": "g20 brasil",
            "keywords": ["g20", "brasil", "cumbre", "lula"]
        },
        {
            "topic": "donald trump",
            "keywords": ["trump", "elecciones", "eeuu", "republicano"]
        }
    ],
    "Poltica": [
        {
            "topic": "congreso nacional",
            "keywords": ["congreso", "diputados", "senadores", "leyes"]
        },
        {
            "topic": "Emanuel Macron",
            "keywords": ["macron", "francia", "europa", "presidente"]
        },
        {
            "topic": "kirchnerismo",
            "keywords": ["kirchner", "peronismo", "poltica", "justicia"]
        },
        {
            "topic": "Estados Unidos",
            "keywords": ["eeuu", "biden", "washington", "poltica"]
        },
        {
            "topic": "Cristina Kirchner",
            "keywords": ["cristina", "kirchner", "senado", "justicialismo"]
        }
    ],
    "Sociedad": [
        {
            "topic": "Lionsgate",
            "keywords": ["lionsgate", "cine", "pelcula", "entertainment"]
        },
        {
            "topic": "Efemrides",
            "keywords": ["efemrides", "historia", "aniversario", "conmemoracin"]
        },
        {
            "topic": "hormigas voladoras",
            "keywords": ["hormigas", "insectos", "naturaleza", "clima"]
        },
        {
            "topic": "clima",
            "keywords": ["temperatura", "lluvia", "pronstico", "meteorologa"]
        },
        {
            "topic": "Andrea Giunta",
            "keywords": ["arte", "cultura", "exposicin", "museo"]
        }
    ]
}

# Define cross-section topics with associated keywords
CROSS_SECTION_TOPICS = [
    {
        "topic": "crisis econmica",
        "keywords": ["crisis", "economa", "inflacin", "recesin"]
    },
    {
        "topic": "presupuesto nacional",
        "keywords": ["presupuesto", "gasto", "congreso", "fiscal"]
    },
    {
        "topic": "polticas pblicas",
        "keywords": ["poltica", "estado", "gestin", "gobierno"]
    },
    {
        "topic": "impacto social",
        "keywords": ["social", "sociedad", "impacto", "comunidad"]
    }
]


def get_topic_variations(topic_info: Dict) -> List[Dict]:
    """
    Generate variations of a topic with associated keywords.

    Parameters
    ----------
    topic_info : Dict
        Dictionary containing topic and its keywords

    Returns
    -------
    List[Dict]
        List of topic variations with keywords
    """
    base_topic = topic_info["topic"]
    variations = [
        f"noticias sobre {base_topic}",
        f"informacin de {base_topic}",
        f"ltimas noticias de {base_topic}",
        f"actualidad sobre {base_topic}",
        base_topic
    ]

    return [
        {
            "prompt": variation,
            "keywords": topic_info["keywords"]
        }
        for variation in variations
    ]


def get_keyword_scores_from_db(
    db_session: Session,
    keywords: List[str],
    min_articles: int = 5
) -> Dict[str, float]:
    """
    Get average scores for keywords from the database.

    Parameters
    ----------
    db_session : Session
        Database session
    keywords : List[str]
        List of keywords to look up
    min_articles : int
        Minimum number of articles containing the keyword

    Returns
    -------
    Dict[str, float]
        Dictionary mapping keywords to their average scores
    """
    # Query processed articles
    stmt = select(ProcessedArticle)
    results = db_session.execute(stmt).fetchall()

    keyword_scores = {}
    for keyword in keywords:
        scores = []
        for result in results:
            processed_article = result[0]
            if processed_article.keywords:
                parsed_keywords = parse_keywords(processed_article.keywords)
                for kw, score in parsed_keywords:
                    if kw.lower() == keyword.lower():
                        scores.append(score)

        if len(scores) >= min_articles:
            keyword_scores[keyword] = sum(scores) / len(scores)

    return keyword_scores


def generate_test_queries(
    db_session: Session,
    dates: Optional[List[str]] = None,
    sections: Optional[List[str]] = None,
    include_cross_section: bool = True,
    queries_per_section: int = 5,
    min_keyword_score: float = 0.1
) -> List[Dict]:
    """
    Generate a comprehensive set of test queries with sections and keywords.

    Parameters
    ----------
    db_session : Session
        Database session for getting keyword scores
    dates : Optional[List[str]]
        List of dates in YYYY-MM-DD format
    sections : Optional[List[str]]
        List of section names
    include_cross_section : bool
        Whether to include cross-section topics
    queries_per_section : int
        Number of queries to generate per section
    min_keyword_score : float
        Minimum score threshold for including keywords

    Returns
    -------
    List[Dict]
        Generated test queries with keywords
    """
    if not dates:
        today = datetime.now()
        dates = [
            (today - timedelta(days=i)).strftime('%Y-%m-%d')
            for i in range(7)
        ]

    if not sections:
        sections = list(SECTION_TOPICS.keys())

    queries = []

    # Generate section-specific queries
    for section in sections:
        section_topics = SECTION_TOPICS[section]
        selected_topics = random.sample(
            section_topics,
            min(queries_per_section, len(section_topics))
        )

        for topic_info in selected_topics:
            # Get keyword scores from database
            keyword_scores = get_keyword_scores_from_db(db_session, topic_info["keywords"])
            filtered_keywords = [
                k for k in topic_info["keywords"]
                if k in keyword_scores and keyword_scores[k] >= min_keyword_score
            ]

            # Generate variations with both prompt and keywords
            variations = get_topic_variations({
                "topic": topic_info["topic"],
                "keywords": filtered_keywords
            })

            # Add queries with date and section
            for variation in variations:
                if dates:
                    date = random.choice(dates)
                    queries.append({
                        "prompt": variation["prompt"],
                        "keywords": variation["keywords"],
                        "date": date,
                        "section": section,
                        "min_keyword_score": min_keyword_score
                    })

                # Add keyword-only query
                queries.append({
                    "prompt": None,
                    "keywords": variation["keywords"],
                    "date": None,
                    "section": section,
                    "min_keyword_score": min_keyword_score
                })

    # Add cross-section queries
    if include_cross_section:
        for topic_info in CROSS_SECTION_TOPICS:
            # Get keyword scores from database
            keyword_scores = get_keyword_scores_from_db(db_session, topic_info["keywords"])
            filtered_keywords = [
                k for k in topic_info["keywords"]
                if k in keyword_scores and keyword_scores[k] >= min_keyword_score
            ]

            variations = get_topic_variations({
                "topic": topic_info["topic"],
                "keywords": filtered_keywords
            })

            for variation in variations:
                # Add date-specific query
                if dates:
                    date = random.choice(dates)
                    queries.append({
                        "prompt": variation["prompt"],
                        "keywords": variation["keywords"],
                        "date": date,
                        "section": None,
                        "min_keyword_score": min_keyword_score
                    })

                # Add keyword-only query
                queries.append({
                    "prompt": None,
                    "keywords": variation["keywords"],
                    "date": None,
                    "section": None,
                    "min_keyword_score": min_keyword_score
                })

    return queries


def generate_test_set_summary(queries: List[Dict]) -> Dict:
    """
    Generate summary statistics for the test set.

    Parameters
    ----------
    queries : List[Dict]
        List of generated queries

    Returns
    -------
    Dict
        Summary statistics
    """
    return {
        'total_queries': len(queries),
        'by_section': {
            section: len([q for q in queries if q.get('section') == section])
            for section in SECTION_TOPICS.keys()
        },
        'query_types': {
            'semantic_only': len([q for q in queries if q.get('prompt') and not q.get('keywords')]),
            'keyword_only': len([q for q in queries if q.get('keywords') and not q.get('prompt')]),
            'combined': len([q for q in queries if q.get('prompt') and q.get('keywords')]),
        },
        'with_date': len([q for q in queries if q.get('date')]),
        'with_section': len([q for q in queries if q.get('section')]),
        'cross_section': len([q for q in queries if not q.get('section')])
    }


def main():
    """Generate a test set and save it."""
    import argparse
    from config import SessionLocal

    parser = argparse.ArgumentParser(description='Generate evaluation test set')
    parser.add_argument('--output', type=str, required=True,
                        help='Output directory for test set')
    parser.add_argument('--queries-per-section', type=int, default=5,
                        help='Number of queries to generate per section')
    parser.add_argument('--no-cross-section', action='store_true',
                        help='Disable cross-section topics')
    parser.add_argument('--min-keyword-score', type=float, default=0.1,
                        help='Minimum score threshold for including keywords')

    args = parser.parse_args()

    # Initialize database session
    session = SessionLocal()

    try:
        # Generate queries
        queries = generate_test_queries(
            db_session=session,
            queries_per_section=args.queries_per_section,
            include_cross_section=not args.no_cross_section,
            min_keyword_score=args.min_keyword_score
        )

        # Save queries
        output_dir = Path(args.output)
        output_dir.mkdir(exist_ok=True)

        queries_file = output_dir / 'test_queries.json'
        with open(queries_file, 'w') as f:
            json.dump(queries, f, indent=2)

        # Generate and save summary
        summary = generate_test_set_summary(queries)
        summary_file = output_dir / 'test_set_summary.json'
        with open(summary_file, 'w') as f:
            json.dump(summary, f, indent=2)

        print(f"Generated {len(queries)} test queries")
        print("\nQuery Distribution:")
        print(f"Semantic-only queries: {summary['query_types']['semantic_only']}")
        print(f"Keyword-only queries: {summary['query_types']['keyword_only']}")
        print(f"Combined queries: {summary['query_types']['combined']}")
        print(f"\nSaved to {queries_file}")
        print(f"Summary saved to {summary_file}")

    finally:
        session.close()


if __name__ == '__main__':
    main()

================
File: scripts/index_articles.py
================
"""
Article Indexing Script

This script indexes articles using various embedding methods and stores them in Qdrant.
"""

import argparse
from typing import List, Dict
import numpy as np
from tqdm import tqdm
from dotenv import load_dotenv
from qdrant_client.models import (
    Distance,
    VectorParams,
    PointStruct
)
from config import SessionLocal
from storage.data_loader import load_articles_from_db
from utils.logging_config import setup_logging
from utils.common import load_config, get_qdrant_client, get_embedder

# Set up logger
logger = setup_logging("indexer")


def process_articles(articles: List[Dict], embedder, batch_size: int = 32) -> List[np.ndarray]:
    """
    Process articles in batches and return embeddings.

    Parameters
    ----------
    articles : List[Dict]
        List of articles to process
    embedder : BaseEmbedder
        Embedder instance to use
    batch_size : int, optional
        Size of batches for processing

    Returns
    -------
    List[np.ndarray]
        List of embedding vectors
    """
    embeddings = []

    # Process in batches
    total_batches = (len(articles) + batch_size - 1) // batch_size
    for i in tqdm(range(0, len(articles), batch_size), total=total_batches, desc="Processing articles"):
        batch = articles[i:i + batch_size]
        try:
            batch_embeddings = [embedder.embed(article['content']) for article in batch]
            embeddings.extend(batch_embeddings)
        except Exception as e:
            logger.error(f"Error processing batch {i // batch_size}: {str(e)}")
            raise

    return embeddings


def main():
    parser = argparse.ArgumentParser(description='Index articles in Qdrant with different embedding methods')
    parser.add_argument('--embedder-type', required=True,
                        choices=['tfidf', 'bm25', 'dpr', 'sbert', 'minilm'],
                        help='Type of embedder to use')
    parser.add_argument('--local', action='store_true',
                        help='Use local Qdrant instance')
    parser.add_argument('--use-processed', action='store_true',
                        help='Use processed articles instead of raw articles')
    parser.add_argument('--batch-size', type=int,
                        help='Batch size for processing')
    parser.add_argument('--min-keyword-score', type=float, default=0.0,
                        help='Minimum score threshold for including keywords')

    args = parser.parse_args()

    try:
        # Load environment variables and configuration
        load_dotenv()
        config = load_config()

        # Initialize database connection
        logger.info("Connecting to database...")
        session = SessionLocal()

        # Initialize Qdrant client
        logger.info("Connecting to Qdrant...")
        qdrant = get_qdrant_client(local=args.local)

        # Get batch size from args or config
        batch_size = args.batch_size or config['processing']['batch_size']

        try:
            # Load articles with keyword score filtering
            logger.info("Loading articles from database...")
            articles = load_articles_from_db(
                session,
                use_processed=args.use_processed,
                min_words=config['processing']['min_words'],
                max_words=config['processing']['max_words'],
                min_keyword_score=args.min_keyword_score
            )
            logger.info(f"Loaded {len(articles)} articles")

            if not articles:
                logger.warning("No articles found matching the criteria!")
                return

            # Get embedder
            embedder = get_embedder(args.embedder_type, config, articles)

            # Create collection
            logger.info(f"Creating collection {embedder.collection_name}...")
            qdrant.recreate_collection(
                collection_name=embedder.collection_name,
                vectors_config=VectorParams(
                    size=embedder.dimension,
                    distance=Distance.COSINE
                )
            )

            # Process articles and get embeddings
            logger.info("Processing articles...")
            embeddings = process_articles(articles, embedder, batch_size)

            # Store in Qdrant
            logger.info("Storing articles in Qdrant...")
            points = []
            for idx, (article, embedding) in enumerate(zip(articles, embeddings)):
                published_date = article['published_at'].strftime('%Y-%m-%d') if article['published_at'] else None

                # Split keywords and scores for storage
                keywords = [kw for kw, _ in article['keywords']]
                keyword_scores = [score for _, score in article['keywords']]

                point = PointStruct(
                    id=idx,
                    vector=embedding.tolist(),
                    payload={
                        'original_id': article['id'],
                        'title': article['title'],
                        'section': article['section'],
                        'keywords': keywords,
                        'keyword_scores': keyword_scores,
                        'published_at': published_date,
                        'newspaper': article['newspaper']
                    }
                )
                points.append(point)

            # Insert points in batches to avoid memory issues with large datasets
            upload_batch_size = 100  # Adjust based on your system's memory
            for i in tqdm(range(0, len(points), upload_batch_size), desc="Uploading to Qdrant"):
                batch = points[i:i + upload_batch_size]
                qdrant.upsert(
                    collection_name=embedder.collection_name,
                    points=batch
                )

            logger.info(f"Successfully indexed {len(articles)} articles with {args.embedder_type}")

            # Log keyword statistics
            total_keywords = sum(len(article['keywords']) for article in articles)
            avg_keywords = total_keywords / len(articles) if articles else 0
            logger.info(f"Average keywords per article: {avg_keywords:.2f}")

            # Log score distribution
            all_scores = [score for article in articles for _, score in article['keywords']]
            if all_scores:
                min_score = min(all_scores)
                max_score = max(all_scores)
                avg_score = sum(all_scores) / len(all_scores)
                logger.info(f"Keyword score distribution:")
                logger.info(f"  Min: {min_score:.4f}")
                logger.info(f"  Max: {max_score:.4f}")
                logger.info(f"  Avg: {avg_score:.4f}")

        finally:
            session.close()

    except Exception as e:
        logger.error(f"An error occurred: {str(e)}", exc_info=True)
        raise


if __name__ == "__main__":
    main()

================
File: scripts/manage_qdrant.py
================
"""
Qdrant Management Script

This script provides utilities for managing Qdrant collections, including
listing, cleaning, and deleting collections.
"""

import argparse
from typing import List, Optional
from qdrant_client.http.exceptions import UnexpectedResponse
from tqdm import tqdm
from dotenv import load_dotenv
from utils.logging_config import setup_logging
from utils.common import get_qdrant_client

# Set up logger
logger = setup_logging("qdrant_manager")


def list_collections(client) -> List[str]:
    """
    List all available collections.

    Parameters
    ----------
    client : QdrantClient
        Qdrant client instance

    Returns
    -------
    List[str]
        List of collection names
    """
    try:
        collections = client.get_collections()
        return [col.name for col in collections.collections]
    except UnexpectedResponse as e:
        logger.error(f"Error listing collections: {e}")
        return []


def get_collection_info(client, collection_name: str) -> dict:
    """
    Get detailed information about a collection.

    Parameters
    ----------
    client : QdrantClient
        Qdrant client instance
    collection_name : str
        Name of the collection

    Returns
    -------
    dict
        Collection information
    """
    try:
        info = client.get_collection(collection_name)
        points_count = client.count(collection_name).count
        return {
            "name": collection_name,
            "vector_size": info.config.params.vectors.size,
            "points_count": points_count,
            "status": "green" if info.status == "green" else "not ready"
        }
    except UnexpectedResponse as e:
        logger.error(f"Error getting info for collection {collection_name}: {e}")
        return {}


def delete_collection(client, collection_name: str):
    """
    Delete a specific collection.

    Parameters
    ----------
    client : QdrantClient
        Qdrant client instance
    collection_name : str
        Name of the collection to delete
    """
    try:
        client.delete_collection(collection_name)
        logger.info(f"Collection '{collection_name}' deleted successfully")
    except UnexpectedResponse as e:
        logger.error(f"Error deleting collection {collection_name}: {e}")


def delete_all_collections(client, exclude: Optional[List[str]] = None):
    """
    Delete all collections except excluded ones.

    Parameters
    ----------
    client : QdrantClient
        Qdrant client instance
    exclude : Optional[List[str]]
        List of collection names to exclude from deletion
    """
    exclude = exclude or []
    collections = list_collections(client)

    for collection in tqdm(collections, desc="Deleting collections"):
        if collection not in exclude:
            delete_collection(client, collection)


def main():
    parser = argparse.ArgumentParser(description='Manage Qdrant collections')
    parser.add_argument(
        '--local',
        action='store_true',
        help='Use local Qdrant instance (default is cloud)'
    )

    subparsers = parser.add_subparsers(dest='command', help='Command to execute')

    # List command
    list_parser = subparsers.add_parser('list', help='List all collections')
    list_parser.add_argument(
        '--detailed',
        action='store_true',
        help='Show detailed information about each collection'
    )

    # Delete command
    delete_parser = subparsers.add_parser('delete', help='Delete collections')
    delete_parser.add_argument(
        '--collections',
        nargs='+',
        help='Names of collections to delete (default: all)'
    )
    delete_parser.add_argument(
        '--exclude',
        nargs='+',
        help='Names of collections to exclude from deletion'
    )
    delete_parser.add_argument(
        '--force',
        action='store_true',
        help='Skip confirmation prompt'
    )

    args = parser.parse_args()

    # Load environment variables
    load_dotenv()

    try:
        # Initialize Qdrant client
        client = get_qdrant_client(local=args.local)

        if args.command == 'list':
            collections = list_collections(client)
            if not collections:
                logger.info("No collections found")
                return

            if args.detailed:
                logger.info("\nCollection Details:")
                print("-" * 70)
                for collection in collections:
                    info = get_collection_info(client, collection)
                    print(f"\nCollection: {info['name']}")
                    print(f"Vector Size: {info['vector_size']}")
                    print(f"Points Count: {info['points_count']}")
                    print(f"Status: {info['status']}")
                    print("-" * 70)
            else:
                logger.info("\nAvailable collections:")
                for collection in collections:
                    print(f"- {collection}")

        elif args.command == 'delete':
            if args.collections:
                # Delete specific collections
                if not args.force:
                    confirm = input(
                        f"Are you sure you want to delete these collections: {', '.join(args.collections)}? [y/N] ")
                    if confirm.lower() != 'y':
                        logger.info("Operation cancelled")
                        return

                for collection in args.collections:
                    delete_collection(client, collection)
            else:
                # Delete all collections except excluded
                if not args.force:
                    confirm = input("Are you sure you want to delete ALL collections? [y/N] ")
                    if confirm.lower() != 'y':
                        logger.info("Operation cancelled")
                        return

                delete_all_collections(client, exclude=args.exclude)

        else:
            parser.print_help()

    except Exception as e:
        logger.error(f"An error occurred: {str(e)}", exc_info=True)
        raise


if __name__ == '__main__':
    main()

================
File: scripts/search_news.py
================
"""
Search News Script

This script provides a command-line interface for searching news articles
using semantic search, keyword-based search, or a combination of both.
"""

import argparse
from typing import List, Optional, Dict
from datetime import datetime
from dotenv import load_dotenv
from utils.common import load_config
from storage.qdrant_manager import QdrantManager
from config import SessionLocal
from storage.data_loader import load_articles_from_db


def format_keywords(keywords: List[tuple]) -> str:
    """Format keyword-score pairs for display."""
    return ', '.join([f"{kw} ({score:.3f})" for kw, score in keywords])


def display_results(results: List[Dict], search_type: str, show_scores: bool = True):
    """Display search results in a formatted manner."""
    print(f"\nSearch type: {search_type}")
    print(f"Found {len(results)} results:\n")

    for i, hit in enumerate(results, 1):
        print(f"{i}. [{hit['section']} - {hit['published_at']}] {hit['title']}")
        if show_scores and 'score' in hit:
            print(f"   Similarity Score: {hit['score']:.4f}")
        if hit['keywords']:
            print(f"   Keywords: {format_keywords(hit['keywords'])}")
        print(f"   Newspaper: {hit['newspaper']}\n")


def search_news(
    prompt: Optional[str] = None,
    keywords: Optional[List[str]] = None,
    date: Optional[str] = None,
    section: Optional[str] = None,
    min_keyword_score: float = 0.0,
    match_any_keyword: bool = True,
    limit: int = 20,
    embedder_type: str = "minilm",
    local: bool = True,
    sort_by_keyword_score: bool = False
):
    """Search for news articles using various criteria."""
    # Load environment variables and configuration
    load_dotenv()
    config = load_config()

    # Initialize database session and load articles
    session = SessionLocal()
    try:
        articles = load_articles_from_db(
            session,
            min_words=config['processing']['min_words'],
            max_words=config['processing']['max_words']
        ) if embedder_type in ['tfidf', 'bm25'] else None

        # Initialize embedder
        from utils.common import get_embedder
        embedder = get_embedder(embedder_type, config, articles)

        # Initialize QdrantManager
        if local:
            qdrant = QdrantManager(
                local=True,
                host=config['qdrant']['local']['host'],
                port=config['qdrant']['local']['port']
            )
        else:
            qdrant = QdrantManager(
                local=False,
                url=config['qdrant']['cloud']['url'],
                api_key=config['qdrant']['cloud']['api_key']
            )

        # Prepare filter conditions
        filter_conditions = {}
        if date:
            filter_conditions['date'] = date
        if section:
            filter_conditions['section'] = section

        # Execute search based on search type
        if prompt and keywords:
            # Combined semantic and keyword search
            query_vector = embedder.embed(prompt)
            results = qdrant.search(
                collection_name=embedder.collection_name,
                query_vector=query_vector,
                filter_conditions=filter_conditions,
                keywords=keywords,
                min_keyword_score=min_keyword_score,
                match_any_keyword=match_any_keyword,
                limit=limit
            )
            search_type = "Semantic + Keyword"

        elif prompt:
            # Semantic search only
            query_vector = embedder.embed(prompt)
            results = qdrant.search(
                collection_name=embedder.collection_name,
                query_vector=query_vector,
                filter_conditions=filter_conditions,
                limit=limit
            )
            search_type = "Semantic"

        elif keywords:
            # Keyword search only
            results = qdrant.search_by_keywords(
                collection_name=embedder.collection_name,
                keywords=keywords,
                min_keyword_score=min_keyword_score,
                filter_conditions=filter_conditions,
                match_any_keyword=match_any_keyword,
                limit=limit
            )
            search_type = "Keyword-only"

        else:
            raise ValueError("Either prompt or keywords must be provided")

        # Sort results by keyword score if requested
        if sort_by_keyword_score and keywords:
            results.sort(
                key=lambda x: max(
                    score for kw, score in x['keywords']
                    if kw in keywords
                ) if any(kw in keywords for kw, _ in x['keywords']) else -1,
                reverse=True
            )

        # Display results
        display_results(results, search_type)

    finally:
        session.close()


def main():
    parser = argparse.ArgumentParser(description='Search news articles')

    # Search criteria
    parser.add_argument('--prompt', help='Search query text')
    parser.add_argument('--keywords', nargs='+', help='Keywords to search for')

    # Filters
    parser.add_argument('--date', help='Date filter (YYYY-MM-DD)')
    parser.add_argument('--section', help='Section filter')

    # Keyword options
    parser.add_argument('--min-keyword-score', type=float, default=0.0,
                        help='Minimum keyword score threshold')
    parser.add_argument('--match-any-keyword', action='store_true', default=True,
                        help='Match any keyword instead of all keywords')
    parser.add_argument('--sort-by-keyword-score', action='store_true',
                        help='Sort results by keyword score')

    # Search parameters
    parser.add_argument('--limit', type=int, default=20,
                        help='Number of results')
    parser.add_argument('--embedder', default='minilm',
                        choices=['tfidf', 'bm25', 'dpr', 'sbert', 'minilm'],
                        help='Embedder type')
    parser.add_argument('--local', action='store_true',
                        help='Use local Qdrant')

    args = parser.parse_args()

    if not args.prompt and not args.keywords:
        parser.error("Either --prompt or --keywords must be specified")

    search_news(
        prompt=args.prompt,
        keywords=args.keywords,
        date=args.date,
        section=args.section,
        min_keyword_score=args.min_keyword_score,
        match_any_keyword=True,
        limit=args.limit,
        embedder_type=args.embedder,
        local=args.local,
        sort_by_keyword_score=args.sort_by_keyword_score
    )


if __name__ == "__main__":
    main()

================
File: scripts/visualize_results.py
================
"""
Results Visualization Script

This script generates visualizations and reports from RAG evaluation results.
"""

import argparse
from pathlib import Path
from evaluation.visualization import ResultsVisualizer


def main():
    parser = argparse.ArgumentParser(
        description='Generate visualizations for RAG evaluation results'
    )
    parser.add_argument(
        '--results-dir',
        type=str,
        required=True,
        help='Directory containing evaluation results'
    )
    parser.add_argument(
        '--output-dir',
        type=str,
        required=True,
        help='Directory to save visualizations and report'
    )
    parser.add_argument(
        '--format',
        choices=['html', 'png', 'all'],
        default='all',
        help='Output format for visualizations'
    )

    args = parser.parse_args()

    # Initialize visualizer
    visualizer = ResultsVisualizer(args.results_dir)

    # Create output directory
    output_dir = Path(args.output_dir)
    output_dir.mkdir(exist_ok=True)

    print("Generating HTML report...")
    visualizer.generate_report(output_dir)

    if args.format in ['png', 'all']:
        print("Generating individual plots...")
        # Generate individual plots
        metrics_fig = visualizer.create_metrics_comparison()
        metrics_fig.write_image(output_dir / 'metrics_comparison.png')

        query_fig = visualizer.create_query_type_performance()
        query_fig.write_image(output_dir / 'query_type_performance.png')

        time_fig = visualizer.create_execution_time_plot()
        time_fig.write_image(output_dir / 'execution_time.png')

    print(f"Visualizations generated in {output_dir}")


if __name__ == '__main__':
    main()

================
File: storage/__init__.py
================
"""
Storage Package

This package provides functionality for data storage and retrieval operations,
including database access and vector storage management.

Available Modules
---------------
data_loader
    Functions for loading and filtering articles from the database
qdrant_manager
    Manages interactions with the Qdrant vector database

The storage package handles all data persistence and retrieval operations,
providing a clean interface between the database and the application logic.
"""

from .data_loader import load_articles_from_db
from .qdrant_manager import QdrantManager

__all__ = [
    'load_articles_from_db',
    'QdrantManager'
]

================
File: storage/data_loader.py
================
"""
Data Loader Module

This module provides functionality for loading and filtering articles from
the database. It handles both raw and preprocessed articles, applying
content length constraints and organizing the data for embedding.
"""

from typing import List, Dict, Optional
from sqlalchemy.orm import Session
from sqlalchemy import select
from models.db_models import Article, ProcessedArticle, Newspaper, Section
import re


def parse_keywords(keywords_str: str) -> List[tuple]:
    """
    Parse keywords string into a list of (keyword, score) tuples.

    Parameters
    ----------
    keywords_str : str
        String of keywords in format "(keyword1,score1),(keyword2,score2),..."

    Returns
    -------
    List[tuple]
        List of tuples containing (keyword, score)
    """
    if not keywords_str:
        return []

    # Regular expression to match (keyword,score) pairs
    pattern = r'\((.*?),([\d.]+)\)'
    matches = re.findall(pattern, keywords_str)

    # Convert matches to list of tuples with proper types
    return [(keyword, float(score)) for keyword, score in matches]


def load_articles_from_db(
    db_session: Session,
    use_processed: bool = False,
    min_words: int = 500,
    max_words: int = 20000,
    min_keyword_score: float = 0.0
) -> List[Dict]:
    """
    Load and filter articles from the database.

    Parameters
    ----------
    db_session : Session
        SQLAlchemy session for database operations
    use_processed : bool, optional
        Whether to use preprocessed articles instead of raw ones
    min_words : int, optional
        Minimum word count for an article to be included
    max_words : int, optional
        Maximum word count for an article to be included
    min_keyword_score : float
        Minimum score for keywords to be included

    Returns
    -------
    List[Dict]
        List of dictionaries, each containing article data with keys:
        - id: Article identifier
        - title: Article title
        - content: Article content (processed or raw)
        - section: Section name
        - keywords: List of (keyword, score) tuples
        - published_at: Publication datetime
        - newspaper: Newspaper name
    """
    if use_processed:
        # Start with ProcessedArticle and explicitly specify the join path
        stmt = (
            select(ProcessedArticle, Article, Section, Newspaper)
            .select_from(ProcessedArticle)
            .join(Article, ProcessedArticle.article_id == Article.id)
            .join(Section, Article.section_id == Section.id)
            .join(Newspaper, Article.newspaper_id == Newspaper.id)
        )
    else:
        # Start with Article and join other tables
        stmt = (
            select(Article, Section, Newspaper)
            .select_from(Article)
            .join(Section, Article.section_id == Section.id)
            .join(Newspaper, Article.newspaper_id == Newspaper.id)
            .outerjoin(ProcessedArticle, Article.id == ProcessedArticle.article_id)
        )

    result = db_session.execute(stmt).fetchall()
    articles = []

    for row in result:
        if use_processed:
            processed_article, article, section, newspaper = row
            content = processed_article.processed_content
            title = processed_article.processed_title
            keywords_str = processed_article.keywords
        else:
            article, section, newspaper = row
            content = article.content
            title = article.title
            # If using raw articles and they have a processed version, get keywords from there
            keywords_str = article.processed_article.keywords if article.processed_article else ""

        # Apply word count filter
        word_count = len(content.split())
        if word_count < min_words or word_count > max_words:
            continue

        # Parse and filter keywords
        keywords = parse_keywords(keywords_str)
        filtered_keywords = [
            (keyword, score) for keyword, score in keywords
            if score >= min_keyword_score
        ]

        # Create article dictionary with all necessary fields
        articles.append({
            'id': article.id,
            'title': title,
            'content': content,
            'section': section.name,
            'keywords': filtered_keywords,
            'published_at': article.published_at,
            'newspaper': newspaper.name
        })

    return articles

================
File: storage/qdrant_manager.py
================
"""
Qdrant Manager Module

This module provides a high-level interface for interacting with the Qdrant
vector database, supporting both local (Docker) and cloud deployments.
"""

from typing import List, Dict, Any, Optional
import numpy as np
from qdrant_client import QdrantClient
from qdrant_client.models import (
    Distance,
    VectorParams,
    PointStruct,
    Filter,
    FieldCondition,
    MatchValue,
    Range,
    SearchParams,
    MatchAny
)


class QdrantManager:
    """Manager class for Qdrant vector database operations."""

    def __init__(
        self,
        local: bool = True,
        host: str = "localhost",
        port: int = 6333,
        url: Optional[str] = None,
        api_key: Optional[str] = None
    ):
        """Initialize the Qdrant manager."""
        if local:
            self.client = QdrantClient(host=host, port=port)
        else:
            if not url or not api_key:
                raise ValueError(
                    "Cloud configuration requires both 'url' and 'api_key'"
                )
            self.client = QdrantClient(url=url, api_key=api_key)

    def _build_filter_conditions(
        self,
        filter_conditions: Optional[Dict] = None,
        keywords: Optional[List[str]] = None,
        min_keyword_score: float = 0.0,
        match_any_keyword: bool = True
    ) -> Optional[Filter]:
        """Build Qdrant filter conditions."""
        must_conditions = []

        # Add date and section filters
        if filter_conditions:
            if 'date' in filter_conditions:
                must_conditions.append(
                    FieldCondition(
                        key='published_at',
                        match=MatchValue(value=filter_conditions['date'])
                    )
                )
            if 'section' in filter_conditions:
                must_conditions.append(
                    FieldCondition(
                        key='section',
                        match=MatchValue(value=filter_conditions['section'])
                    )
                )

        # Add keyword filters
        if keywords:
            if match_any_keyword:
                # Match any of the keywords using MatchAny
                must_conditions.append(
                    FieldCondition(
                        key='keywords',
                        match=MatchAny(any=keywords)
                    )
                )
                if min_keyword_score > 0:
                    must_conditions.append(
                        FieldCondition(
                            key='keyword_scores',
                            range=Range(gte=min_keyword_score)
                        )
                    )
            else:
                # Match all keywords
                for keyword in keywords:
                    must_conditions.append(
                        FieldCondition(
                            key='keywords',
                            match=MatchValue(value=keyword)
                        )
                    )
                    if min_keyword_score > 0:
                        must_conditions.append(
                            FieldCondition(
                                key='keyword_scores',
                                range=Range(gte=min_keyword_score)
                            )
                        )

        return Filter(must=must_conditions) if must_conditions else None

    def search(
        self,
        collection_name: str,
        query_vector: np.ndarray,
        filter_conditions: Optional[Dict] = None,
        keywords: Optional[List[str]] = None,
        min_keyword_score: float = 0.0,
        match_any_keyword: bool = True,
        limit: int = 5
    ) -> List[Dict]:
        """
        Search for similar articles in Qdrant with optional filtering.

        Parameters
        ----------
        collection_name : str
            Name of the collection to search in
        query_vector : np.ndarray
            Query vector to search with
        filter_conditions : Optional[Dict]
            Dictionary containing filter conditions (date, section)
        keywords : Optional[List[str]]
            List of keywords to filter by
        min_keyword_score : float
            Minimum score for keyword matches
        match_any_keyword : bool
            If True, matches articles with any of the keywords
        limit : int
            Maximum number of results to return
        """
        search_filter = self._build_filter_conditions(
            filter_conditions,
            keywords,
            min_keyword_score,
            match_any_keyword
        )

        results = self.client.search(
            collection_name=collection_name,
            query_vector=query_vector.tolist(),
            query_filter=search_filter,
            search_params=SearchParams(hnsw_ef=128),
            limit=limit
        )

        return [
            {
                'id': hit.id,
                'score': hit.score,
                'original_id': hit.payload['original_id'],
                'title': hit.payload['title'],
                'section': hit.payload['section'],
                'keywords': list(zip(
                    hit.payload['keywords'],
                    hit.payload['keyword_scores']
                )),
                'published_at': hit.payload['published_at'],
                'newspaper': hit.payload['newspaper']
            }
            for hit in results
        ]

    def search_by_keywords(
        self,
        collection_name: str,
        keywords: List[str],
        min_keyword_score: float = 0.0,
        filter_conditions: Optional[Dict] = None,
        match_any_keyword: bool = True,
        limit: int = 5
    ) -> List[Dict]:
        """
        Search for articles by keywords without requiring a query vector.

        Parameters
        ----------
        collection_name : str
            Name of the collection to search in
        keywords : List[str]
            List of keywords to search for
        min_keyword_score : float
            Minimum score for keyword matches
        filter_conditions : Optional[Dict]
            Dictionary containing filter conditions
        match_any_keyword : bool
            If True, matches articles with any of the keywords
        limit : int
            Maximum number of results to return
        """
        search_filter = self._build_filter_conditions(
            filter_conditions,
            keywords,
            min_keyword_score,
            match_any_keyword
        )

        results = self.client.scroll(
            collection_name=collection_name,
            scroll_filter=search_filter,  # Changed from filter to scroll_filter
            limit=limit
        )[0]  # scroll returns (points, next_page_offset)

        return [
            {
                'id': point.id,
                'original_id': point.payload['original_id'],
                'title': point.payload['title'],
                'section': point.payload['section'],
                'keywords': list(zip(
                    point.payload['keywords'],
                    point.payload['keyword_scores']
                )),
                'published_at': point.payload['published_at'],
                'newspaper': point.payload['newspaper']
            }
            for point in results
        ]

    def get_vectors(
        self,
        collection_name: str,
        ids: List[str]
    ) -> List[dict]:
        """Retrieve vectors for given IDs."""
        points = self.client.retrieve(
            collection_name=collection_name,
            ids=list(map(int, ids)), # If ids are strings, convert to integers
            with_vectors=True
        )
        return points

    def search_similar(
        self,
        collection_name: str,
        vector_id: str,
        threshold: float = 0.75,
        limit: int = 10
    ) -> List[dict]:
        """Search for similar vectors using a reference vector ID."""
        # First get the reference vector
        reference = self.get_vectors(collection_name, [vector_id])[0]

        # Search using the reference vector
        results = self.client.search(
            collection_name=collection_name,
            query_vector=reference.vector,
            score_threshold=threshold,
            limit=limit
        )

        return results

================
File: .gitignore
================
.env
config/config.yaml
*.log
evaluation/results/*
evaluation/visualizations/*

================
File: config.py
================
import os
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Get the database URL from environment variables
DATABASE_URL = os.getenv('DATABASE_URL')

# Create the database engine
engine = create_engine(DATABASE_URL)

# Create a configured "Session" class
SessionLocal = sessionmaker(bind=engine)

================
File: db_qdrant.py
================
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams

client = QdrantClient(host="localhost", port=6333)

def create_index():
    """Crea un ndice para almacenar embeddings en Qdrant."""
    client.recreate_collection(
        collection_name="news_collection",
        vectors_config=VectorParams(
            size=384,  # Tamao del embedding (depende del modelo que uses)
            distance=Distance.COSINE  # Usamos distancia coseno para la bsqueda
        )
    )

================
File: env.sample
================
DATABASE_URL=mysql+mysqlconnector://root:password@localhost/news_db
QDRANT_API_KEY=your_api_key

================
File: index_preprocessed.sh
================
#!/usr/bin/env bash
for embedder in tfidf bm25 dpr sbert minilm; do
    python scripts/index_articles.py --local --embedder-type $embedder --use-processed
done

================
File: index_raw.sh
================
#!/usr/bin/env bash
for embedder in tfidf bm25 dpr sbert minilm; do
    python scripts/index_articles.py --local --embedder-type $embedder
done

================
File: README.md
================
# News Article RAG System

A Retrieval-Augmented Generation (RAG) system for Spanish news articles, implementing multiple embedding strategies and
vector search capabilities with support for keyword-based retrieval.

## Overview

This project implements a RAG system designed to work with Spanish news articles. It provides multiple embedding
approaches and vector search capabilities, allowing for efficient semantic search, keyword-based search, and hybrid
retrieval of news content.

## Features

- Multiple search approaches:
  - Semantic search using embeddings
  - Keyword-based search with relevance scores
  - Hybrid search combining both approaches
  
- Multiple embedding strategies:
  - TF-IDF (Term Frequency-Inverse Document Frequency)
  - BM25 (Best Match 25 algorithm)
  - DPR (Dense Passage Retrieval)
  - SBERT (Spanish-tuned Sentence-BERT)
  - MiniLM (Efficient multilingual embeddings)

- Advanced keyword functionality:
  - Keyword scoring and relevance ranking
  - Keyword extraction and filtering
  - Score-based keyword matching
  - Minimum score thresholds

- Content filtering:
  - Word count constraints (500-20,000 words)
  - Section-based filtering
  - Date-based filtering
  - Keyword score filtering

- Database integration:
  - SQLAlchemy models for articles and processed content
  - Support for both raw and preprocessed articles
  - Keyword storage and retrieval

- Vector storage:
  - Qdrant integration for efficient vector search
  - Metadata filtering capabilities
  - Cosine similarity search
  - Keyword score indexing

## Setup

1. Setup PYTHONPATH environment variable:

```bash
export PYTHONPATH="$(pwd):$(pwd)/../data-mining"
```

2. Create a `.env` file with your configuration:
```plaintext
DATABASE_URL=mysql+mysqlconnector://root:password@localhost/news_db
QDRANT_API_KEY=your_api_key
```

3. Create your config.yaml file based on the sample:

```bash
cp config/config.yaml.sample config/config.yaml
```

Then edit config/config.yaml with your settings:

```yaml
database:
  url: ${DATABASE_URL}

qdrant:
  # For local development (Docker)
  local:
    host: localhost
    port: 6333
  # For production (Cloud)
  cloud:
    url: "https://YOUR-CLUSTER-URL.qdrant.io"
    api_key: ${QDRANT_API_KEY}

embedders:
  tfidf:
    max_features: 384

  sbert:
    model_name: "hiiamsid/sentence_similarity_spanish_es"

  dpr:
    model_name: "facebook/dpr-question_encoder-single-nq-base"

  minilm:
    model_name: "sentence-transformers/all-MiniLM-L6-v2"

processing:
  batch_size: 32
  min_words: 500
  max_words: 20000
```

4. Install dependencies:

```bash
pip install -r requirements.txt
```

## Usage

### Managing Qdrant Collections

List collections:
```bash
# Simple list
python scripts/manage_qdrant.py --local list

# Detailed information
python scripts/manage_qdrant.py --local list --detailed
```

Delete collections:
```bash
# Delete specific collections
python scripts/manage_qdrant.py --local delete --collections news_sbert news_tfidf

# Delete all collections
python scripts/manage_qdrant.py --local delete --force

# Delete all except specific ones
python scripts/manage_qdrant.py --local delete --exclude news_sbert news_tfidf
```

### Indexing Articles

Basic indexing:
```bash
# Index using specific embedder (local Qdrant)
python scripts/index_articles.py --local --embedder-type minilm

# Use processed articles with keyword filtering
python scripts/index_articles.py --local --embedder-type minilm --use-processed --min-keyword-score 0.1

# Specify batch size
python scripts/index_articles.py --local --embedder-type minilm --batch-size 64
```

Multiple embedder indexing:
```bash
# Index with all embedders
for embedder in tfidf bm25 dpr sbert minilm; do
    python scripts/index_articles.py --local --embedder-type $embedder --use-processed
done
```

### Searching Articles

Basic search:
```bash
# Semantic search
python scripts/search_news.py --prompt "Noticias importantes" --embedder minilm --local

# Keyword search
python scripts/search_news.py --keywords "economa" "inflacin" --min-keyword-score 0.2 --local

# Combined search
python scripts/search_news.py --prompt "crisis econmica" --keywords "economa" "inflacin" --local
```

Advanced search options:
```bash
# Search with filters
python scripts/search_news.py --prompt "anlisis econmico" \
    --keywords "g20" "dlar" \
    --date 2024-11-18 \
    --section "Economa" \
    --min-keyword-score 0.3 \
    --match-any-keyword \
    --sort-by-keyword-score \
    --limit 20 \
    --embedder minilm \
    --local
```

### Evaluating Embedders

Generate test set:
```bash
# Basic test set generation
python scripts/generate_test_set.py --output evaluation/test_sets/

# Advanced test set with keyword settings
python scripts/generate_test_set.py \
    --output evaluation/test_sets/ \
    --queries-per-section 10 \
    --min-keyword-score 0.2
```

Run evaluation:
```bash
# Evaluate all embedders
python scripts/evaluate_embeddings.py \
    --local \
    --output evaluation/results/ \
    --keyword-match-threshold 0.3 \
    --min-keyword-score 0.2

# Evaluate specific embedders
python scripts/evaluate_embeddings.py \
    --local \
    --output evaluation/results/ \
    --embedders tfidf sbert \
    --keyword-match-threshold 0.3
```

### Visualizing Results

Generate visualizations:
```bash
# Generate complete report
python scripts/visualize_results.py \
    --results-dir evaluation/results \
    --output-dir evaluation/visualizations

# Generate specific formats
python scripts/visualize_results.py \
    --results-dir evaluation/results \
    --output-dir evaluation/visualizations \
    --format html  # or 'png' or 'all'
```

## Understanding Keyword Scores

Keywords in articles are stored with relevance scores in the format:
```
(keyword1,0.306),(keyword2,0.216),(keyword3,0.205)
```

- Scores range from 0 to 1, indicating keyword relevance
- Higher scores indicate stronger keyword relevance
- Typical threshold ranges:
  - 0.3+ : Strong relevance
  - 0.2-0.3 : Moderate relevance
  - <0.2 : Weak relevance

## Common Issues

1. **Keyword Score Filtering**: If no results are returned when using keyword search, try lowering the `min-keyword-score` threshold.

2. **Memory Issues**: When processing large datasets with keywords, adjust the batch sizes in index_articles.py and evaluate_embeddings.py.

3. **Missing Test Queries**: Ensure you've generated test queries with appropriate keyword settings:
```bash
python scripts/generate_test_set.py --output evaluation/test_sets/ --min-keyword-score 0.2
```

4. **Qdrant Connection**: For local development, ensure Qdrant is running. For cloud, verify your API key is set in .env.

## Development

### Common Utilities

Common functionalities are centralized in `scripts/utils/common.py`:
- Configuration loading
- Qdrant client initialization
- Embedder initialization
- Keyword processing utilities

Example:
```python
from utils.common import load_config, get_qdrant_client, get_embedder

# Load configuration
config = load_config()

# Get Qdrant client
qdrant = get_qdrant_client(local=True)

# Initialize embedder with keyword support
embedder = get_embedder('minilm', config, articles)
```

================
File: requirements.txt
================
numpy==2.0.2
torch==2.5.1
transformers==4.46.2
sentence-transformers==3.3.0
scikit-learn==1.5.2
rank_bm25==0.2.2
qdrant-client==1.12.1
sqlalchemy==2.0.36
mysql-connector-python==9.1.0
PyYAML==6.0.2
tqdm==4.67.0
pytest==8.3.3
python-dotenv==1.0.1
pandas==2.2.3
plotly==5.24.1
kaleido==0.4.1
